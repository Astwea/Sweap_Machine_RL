import gymnasium as gym
import torch
import isaaclab.sim as sim_utils
from isaaclab.assets import Articulation
from isaaclab.envs import DirectRLEnv
from isaaclab.sensors import ContactSensor
from isaaclab.sim.spawners.from_files import spawn_ground_plane,spawn_from_usd, UsdFileCfg, GroundPlaneCfg
from isaaclab.utils.assets import ISAAC_NUCLEUS_DIR, ISAACLAB_NUCLEUS_DIR
from isaaclab.markers import VisualizationMarkers, VisualizationMarkersCfg
from isaaclab.assets import AssetBaseCfg
from .mydog_marl_env_cfg import MydogMarlEnvCfg

try:
    from isaacsim.util.debug_draw import _debug_draw as debug_draw
    from isaaclab.devices import Se2Keyboard, Se2KeyboardCfg
    debug_draw_available = True
except ImportError:
    debug_draw_available = False
    print("Debug draw is not available. Please check your Isaac Sim installation.")

import math
from isaaclab.utils.math import quat_from_angle_axis
from torch.utils.tensorboard import SummaryWriter
import time
import traceback

import torch
import math
import matplotlib.pyplot as plt
from scipy.interpolate import CubicSpline
import numpy as np
import random
from .mpc_controller import DifferentialDriveMPC
from concurrent.futures import ThreadPoolExecutor

def define_markers(path, idx) -> VisualizationMarkers:
    """Define markers with various different shapes."""
    if idx == 0:
        markers={
                "sphere": sim_utils.SphereCfg(
                    radius=0.5,
                    visual_material=sim_utils.PreviewSurfaceCfg(diffuse_color=(0.0, 1.0, 0.0)),
                )
            }
    elif idx == 1:
        markers={
                "arrow": sim_utils.UsdFileCfg(
                    usd_path=f"{ISAAC_NUCLEUS_DIR}/Props/UIElements/arrow_x.usd",
                    scale=(0.5, 0.5, 0.5),
                    visual_material=sim_utils.PreviewSurfaceCfg(diffuse_color=(0.0, 0.0, 1.0)),
                )
            }
    elif idx == 2:
        markers={
                "arrow1": sim_utils.UsdFileCfg(
                    usd_path=f"{ISAAC_NUCLEUS_DIR}/Props/UIElements/arrow_x.usd",
                    scale=(0.5, 0.5, 0.5),
                    visual_material=sim_utils.PreviewSurfaceCfg(diffuse_color=(0.0, 1.0, 0.0)),
                )
            }
    marker_cfg = VisualizationMarkersCfg(
        prim_path=f"/Visuals/myMarkers/{path}",
        markers=markers
    
    )
    return VisualizationMarkers(marker_cfg)

def mpc_worker(args):
    pos, yaw, start_idx, traj_np, horizon, step_dt = args
    mpc = DifferentialDriveMPC(horizon=horizon, dt=step_dt)
    sub_traj = traj_np[start_idx:start_idx + horizon + 1]
    if len(sub_traj) < horizon + 1:
        pad = np.tile(sub_traj[-1], (horizon + 1 - len(sub_traj), 1))
        sub_traj = np.concatenate([sub_traj, pad], axis=0)
    try:
        v, w = mpc.solve((pos[0], pos[1], yaw), sub_traj)
    except:
        v, w = 0.0, 0.0
    return [v, w]

class MydogMarlEnv(DirectRLEnv):
    # 1. é…ç½®åˆå§‹åŒ–
    cfg: MydogMarlEnvCfg

    def __init__(self, cfg: MydogMarlEnvCfg, render_mode: str | None = None, **kwargs):
        # 1.1 åˆå§‹åŒ–çˆ¶ç±»
        super().__init__(cfg, render_mode, **kwargs)

        # 1.2 åˆå§‹åŒ–åŠ¨ä½œå­˜å‚¨
        # - è®°å½•å½“å‰å’Œå‰ä¸€æ¬¡çš„åŠ¨ä½œï¼Œç”¨äºè®¡ç®—å¥–åŠ±å’ŒåŠ¨æ€æ§åˆ¶
        self._actions = torch.zeros(self.num_envs, 2, device=self.device)  # (çº¿é€Ÿåº¦, è§’é€Ÿåº¦)
        self.teacher_actions = torch.zeros(self.num_envs, 2, device=self.device)  # (çº¿é€Ÿåº¦, è§’é€Ÿåº¦)
        self._previous_actions = torch.zeros(self.num_envs, 2, device=self.device)


        self.arrow_visual = define_markers(path="arrows", idx=1)
        self.target_arrow_visual = define_markers(path="target_arrows", idx=2)

        self._commands = torch.zeros(self.num_envs, 2, device=self.device)  # (x, y, z)
        self._trajectories = torch.zeros(self.num_envs, self.cfg.num_waypoints*self.cfg.num_interp, 2, device=self.device)
        self._current_wp_idx = torch.ones(self.num_envs, dtype=torch.long, device=self.device)
        self._prev_wp_idx = torch.zeros(self.num_envs, dtype=torch.long, device=self.device)
        self.seed = 10
        self.epoch = 0
        self.turn_mask = torch.zeros(self.num_envs, dtype=torch.bool, device=self.device)
        self.headerror = torch.zeros(self.num_envs, device=self.device)
        self.dist_to_target = None
        self._prev_dist_to_target = torch.zeros(self.num_envs, device=self.device)
        self.target_orientations = None
        self.positions = self._robot.data.root_state_w[:, :2]
        # ç«‹å³æ£€æŸ¥ä½ç½®æ•°æ®æ˜¯å¦æœ‰NaN/Infï¼ˆåœ¨åˆå§‹åŒ–æ—¶å°±æ£€æŸ¥ï¼‰
        if isinstance(self.positions, torch.Tensor):
            if torch.isnan(self.positions).any() or torch.isinf(self.positions).any():
                print(f"ğŸš¨ è­¦å‘Šï¼šåˆå§‹åŒ–æ—¶ä½ç½®æ•°æ®åŒ…å«NaN/Infï¼")
                self.positions = torch.where(torch.isnan(self.positions) | torch.isinf(self.positions),
                                           torch.zeros_like(self.positions), self.positions)
        self.last_pos = self.positions.clone()
        self.cos_phi = torch.zeros(self.num_envs, 1, device=self.device)
        self.sin_phi = torch.zeros(self.num_envs, 1, device=self.device)
        # 1.3 åˆå§‹åŒ–æ—¥å¿—è®°å½•
        # - è®°å½•æ¯ä¸ªå›åˆä¸­çš„å…³é”®æ€§èƒ½æŒ‡æ ‡
        print(f"{cfg.tensorboard_dir}/{time.strftime('%Y-%m-%d_%H-%M-%S')}/summary ----------------------------------------------------------------")
        self.writer = SummaryWriter(log_dir=f"{cfg.tensorboard_dir}/{time.strftime('%Y-%m-%d_%H-%M-%S')}/summary")
        self.begin_time = time.time()
        self.global_step = 0
        self.epoch_step = 0
        self.episode_count = 0  # å›åˆç»“æŸæ¬¡æ•°è®¡æ•°å™¨
        
        # åˆå§‹åŒ–å„ç§æŒ‡æ ‡è®°å½•
        self._episode_sums = {
            key: torch.zeros(self.num_envs, dtype=torch.float, device=self.device) 
            for key in ["tracking_reward","direction_reward","goal_bias","action_rate_penalty","action_mag_penalty","imitation_reward"]
        }
        
        # æ·»åŠ æ›´å¤šç›‘æ§æŒ‡æ ‡
        self._episode_metrics = {
            key: torch.zeros(self.num_envs, dtype=torch.float, device=self.device) 
            for key in ["episode_length", "success_rate", "total_distance", "avg_speed", "max_lateral_error", "final_distance"]
        }
        
        # æ€§èƒ½ç»Ÿè®¡
        self._performance_stats = {
            "fps": 0.0,
            "step_time": 0.0,
            "reward_time": 0.0,
            "action_time": 0.0
        }
        
        # è®­ç»ƒç»Ÿè®¡
        self._training_stats = {
            "episode_count": 0,
            "total_episodes": 0,
            "best_reward": float('-inf'),
            "avg_reward": 0.0
        }
        self.joint_idx, _ = self._robot.find_joints(['left_wheel_joint', 'right_wheel_joint'])
        self.positions = self._robot.data.root_state_w[:, :2]
        # æ³¨æ„ï¼šæ­¤æ—¶_always_check_nanå¯èƒ½è¿˜æœªåˆå§‹åŒ–ï¼Œä½¿ç”¨ç®€å•æ£€æŸ¥
        if isinstance(self.positions, torch.Tensor):
            if torch.isnan(self.positions).any() or torch.isinf(self.positions).any():
                print(f"ğŸš¨ è­¦å‘Šï¼šåˆå§‹åŒ–æ—¶ä½ç½®æ•°æ®åŒ…å«NaN/Infï¼")
                self.positions = torch.where(torch.isnan(self.positions) | torch.isinf(self.positions),
                                           torch.zeros_like(self.positions), self.positions)
        
        self.yaw = self._robot.data.root_state_w[:, 3:7]
        if isinstance(self.yaw, torch.Tensor):
            if torch.isnan(self.yaw).any() or torch.isinf(self.yaw).any():
                print(f"ğŸš¨ è­¦å‘Šï¼šåˆå§‹åŒ–æ—¶yawæ•°æ®åŒ…å«NaN/Infï¼")
                self.yaw = torch.where(torch.isnan(self.yaw) | torch.isinf(self.yaw),
                                      torch.zeros_like(self.yaw), self.yaw)
        
        self.mpc = [DifferentialDriveMPC(horizon=10, dt=self.step_dt) for _ in range(self.num_envs)]
        
        # === å¥–åŠ±å¹³æ»‘ç³»ç»Ÿåˆå§‹åŒ– ===
        # ç›®æ ‡ç‚¹åˆ‡æ¢æ£€æµ‹
        self._prev_wp_idx = torch.zeros(self.num_envs, dtype=torch.long, device=self.device)
        self._target_switch_detected = torch.zeros(self.num_envs, dtype=torch.bool, device=self.device)
        
        # å¥–åŠ±å¹³æ»‘å†å²çŠ¶æ€
        self._prev_rewards = {
            'heading_reward': None,
            'progress_reward': None,
            'lateral_penalty': None,
            'goal_reward': None,
        }
        
        # å¹³æ»‘å‚æ•° - ä¼˜åŒ–åçš„å‚æ•°
        self.smoothing_factor = 0.15  # å¹³æ»‘å› å­ - å¢åŠ å¹³æ»‘æ•ˆæœ
        self.transition_smoothing_factor = 0.4  # ç›®æ ‡ç‚¹åˆ‡æ¢æ—¶çš„å¹³æ»‘å› å­ - å¢å¼ºåˆ‡æ¢å¹³æ»‘
        
        # æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥ - å¿…é¡»åœ¨æ‰€æœ‰åˆå§‹åŒ–ä¹‹å‰è®¾ç½®
        self.debug_mode = True  # å¯ç”¨è°ƒè¯•æ¨¡å¼
        self.nan_inf_count = {'obs': 0, 'reward': 0, 'action': 0, 'quat': 0, 'trajectory': 0, 'position': 0, 'tensorboard': 0}
        
        # NaN/Inf æº¯æºç³»ç»Ÿ
        self.nan_trace_log = []  # è®°å½•æ‰€æœ‰ NaN/Inf äº‹ä»¶çš„è¯¦ç»†æ—¥å¿—
        self.nan_first_occurrence = {}  # è®°å½•æ¯ä¸ªå˜é‡ç¬¬ä¸€æ¬¡å‡ºç° NaN çš„ä½ç½®
        
        # å…¨å±€NaNæ£€æµ‹å¼€å…³ - å§‹ç»ˆå¯ç”¨ï¼Œå³ä½¿åœ¨åˆå§‹åŒ–é˜¶æ®µ
        self._always_check_nan = True  # å¼ºåˆ¶å¯ç”¨NaNæ£€æµ‹ï¼Œå³ä½¿debug_modeå…³é—­
        
        # === è¯¾ç¨‹å­¦ä¹ ç³»ç»Ÿåˆå§‹åŒ– ===
        self.curriculum_enabled = self.cfg.enable_curriculum
        self.curriculum_stage = 0  # å½“å‰è¯¾ç¨‹é˜¶æ®µ
        
        # å®šä¹‰è¯¾ç¨‹å­¦ä¹ é˜¶æ®µï¼ˆåŸºäºæˆåŠŸç‡å’Œæœ€å°å›åˆæ•°æ§åˆ¶åˆ‡æ¢ï¼‰
        # æ³¨æ„ï¼šç”±äºæœºå™¨äººç§»åŠ¨é€Ÿåº¦æ…¢ï¼ˆ0.1 m/sï¼‰ï¼Œå›åˆé•¿åº¦å·²ç›¸åº”å¢åŠ 
        # åŸé…ç½®ï¼š10s, 12s, 15s â†’ æ–°é…ç½®ï¼š40s, 50s, 60sï¼ˆçº¦4å€æ¯”ä¾‹ï¼‰
        # è¿™æ ·æœºå™¨äººæœ‰è¶³å¤Ÿæ—¶é—´å®Œæˆä»»åŠ¡ï¼Œé¿å…æ¢¯åº¦æ¶ˆå¤±é—®é¢˜
        self.curriculum_stages = {
            0: {  # é˜¶æ®µ1: åŸºç¡€ç›´çº¿è·Ÿè¸ª
                'num_waypoints': 2,
                'num_interp': 4,
                'step_size': 0.5,
                'episode_length_s': 40.0,  # ä»10ç§’å¢åŠ åˆ°40ç§’ï¼Œé€‚åº”æ…¢é€Ÿç§»åŠ¨ï¼ˆ0.1 m/sï¼‰
                'traj_track_scale': 20.0,
                'lateral_error_scale': 30.0,
                'direction_scale': 8.0,
                'stage_name': 'basic_straight'
            },
            1: {  # é˜¶æ®µ2: ç®€å•è½¬å¼¯
                'num_waypoints': 3,
                'num_interp': 6,
                'step_size': 0.8,
                'episode_length_s': 50.0,  # ä»12ç§’å¢åŠ åˆ°50ç§’ï¼Œé€‚åº”æ…¢é€Ÿç§»åŠ¨
                'traj_track_scale': 15.0,
                'lateral_error_scale': 25.0,
                'direction_scale': 6.0,
                'stage_name': 'simple_turn'
            },
            2: {  # é˜¶æ®µ3: å¤æ‚è½¨è¿¹
                'num_waypoints': 5,
                'num_interp': 12,
                'step_size': 1.0,
                'episode_length_s': 60.0,  # ä»15ç§’å¢åŠ åˆ°60ç§’ï¼Œä¸ä¸»é…ç½®ä¸€è‡´
                'traj_track_scale': 15.0,
                'lateral_error_scale': 25.0,
                'direction_scale': 5.0,
                'stage_name': 'complex_trajectory'
            }
        }
        # è¯¾ç¨‹å­¦ä¹ é…ç½®å‚æ•°
        self.curriculum_success_rate_threshold = cfg.curriculum_success_rate_threshold
        self.curriculum_min_episodes_per_stage = cfg.curriculum_min_episodes_per_stage
        self.curriculum_success_window_size = cfg.curriculum_success_window_size
        
        # è¯¾ç¨‹å­¦ä¹ ç»Ÿè®¡
        self.curriculum_stats = {
            'stage_0_steps': 0,
            'stage_1_steps': 0,
            'stage_2_steps': 0,
            'stage_0_success_rate': 0.0,
            'stage_1_success_rate': 0.0,
            'stage_2_success_rate': 0.0,
        }
        
        # æˆåŠŸç‡å†å²è®°å½•ï¼ˆç”¨äºæ»‘åŠ¨çª—å£è¯„ä¼°ï¼‰
        self.success_history = []  # è®°å½•æœ€è¿‘çš„æˆåŠŸ/å¤±è´¥å†å²
        
        # åˆå§‹åŒ–å®Œæˆåæ£€æŸ¥ä½ç½®æ•°æ®
        self.positions = self._check_numerical_stability(self.positions, 'position')
        self.last_pos = self._check_numerical_stability(self.last_pos, 'position')
        
        # åˆå§‹åŒ–è¯¾ç¨‹å­¦ä¹ å‚æ•°
        self._init_curriculum_parameters()

        if debug_draw_available:
            self.debug_draw = debug_draw.acquire_debug_draw_interface()
            keyboard_cfg = Se2KeyboardCfg(v_y_sensitivity=0.8)
            self.keyboard = Se2Keyboard(keyboard_cfg)
        else:
            self.debug_draw = None
            self.keyboard = None
        self.count = 0
        self.finished_mask = None
        
    # 2. åœºæ™¯è®¾ç½®
    def _setup_scene(self):
        # 2.1 åˆå§‹åŒ–æœºå™¨äººæ¨¡å‹
        self._robot = Articulation(self.cfg.robot)
        # spawn_ground_plane(prim_path="/World/ground", cfg=Envconfig())
        spawn_ground_plane(
            prim_path="/World/ground",
            cfg=GroundPlaneCfg(color=(0.5, 0.5, 0.5),
                               size=(300, 300))
        )
        self.scene.articulations["robot"] = self._robot
        
        # 2.2 åˆå§‹åŒ–æ¥è§¦ä¼ æ„Ÿå™¨
        # self._contact_sensor = ContactSensor(self.cfg.contact_sensor)
        # self.scene.sensors["contact_sensor"] = self._contact_sensor
        # self.cfg.terrain.num_envs = self.scene.cfg.num_envs
        # self.cfg.terrain.env_spacing = self.scene.cfg.env_spacing
        # self._terrain = self.cfg.terrain.class_type(self.cfg.terrain)
        
        # 2.3 å…‹éš†ç¯å¢ƒ
        # - åˆ›å»ºå¤šä¸ªç¯å¢ƒå®ä¾‹ï¼Œæé«˜å¹¶è¡Œæ•ˆç‡
        self.scene.clone_environments(copy_from_source=False)
        light_cfg = sim_utils.DomeLightCfg(intensity=2000.0, color=(0.75, 0.75, 0.75))
        light_cfg.func("/World/Light", light_cfg)
    # 3. ç‰©ç†æ­¥å‰å¤„ç†

    def quaternion_to_forward_vector(self, quaternions):
        # æå–å››å…ƒæ•° (qx, qy, qz, qw)
        qw, qx, qy, qz = quaternions[:, 0], quaternions[:, 1], quaternions[:, 2], quaternions[:, 3]

        # è®¡ç®—æ­£å‰æ–¹æ–¹å‘å‘é‡
        forward_x = 2 * (qx * qz + qw * qy)
        forward_y = 2 * (qy * qz - qw * qx)
        forward_z = 1 - 2 * (qx ** 2 + qy ** 2)

        return torch.stack([forward_x, forward_y, forward_z], dim=1)


    def quaternion_to_yaw(self,quat):
        """
        è®¡ç®—å››å…ƒæ•° (w, x, y, z) å¯¹åº”çš„ yaw è§’åº¦
        """
        w, x, y, z = quat[:, 0], quat[:, 1], quat[:, 2], quat[:, 3]
        
        # æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
        quat = self._check_numerical_stability(quat, 'quat')
        
        # ç¡®ä¿å››å…ƒæ•°å½’ä¸€åŒ–ï¼Œé˜²æ­¢é™¤é›¶å’Œsqrtè´Ÿæ•°
        # å…ˆæ£€æŸ¥è¾“å…¥æ˜¯å¦æœ‰NaN/Inf
        w, x, y, z = self._check_numerical_stability(w, 'quat_w_before_norm'), \
                     self._check_numerical_stability(x, 'quat_x_before_norm'), \
                     self._check_numerical_stability(y, 'quat_y_before_norm'), \
                     self._check_numerical_stability(z, 'quat_z_before_norm')
        
        # è®¡ç®—normï¼Œç¡®ä¿è¾“å…¥éè´Ÿï¼ˆé˜²æ­¢sqrtè´Ÿæ•°äº§ç”ŸNaNï¼‰
        norm_sq = w**2 + x**2 + y**2 + z**2
        norm_sq = torch.clamp(norm_sq, min=0.0)  # ç¡®ä¿éè´Ÿ
        norm = torch.sqrt(norm_sq + 1e-10)  # æ·»åŠ å°å€¼é˜²æ­¢sqrt(0)çš„æ•°å€¼é—®é¢˜
        norm = torch.clamp(norm, min=1e-8)  # é¿å…é™¤é›¶ï¼Œç¡®ä¿æœ€å°å€¼
        # æ£€æŸ¥normæ˜¯å¦æœ‰å¼‚å¸¸å€¼
        norm = self._check_numerical_stability(norm, 'quat_norm')
        w, x, y, z = w/norm, x/norm, y/norm, z/norm
        # æ£€æŸ¥å½’ä¸€åŒ–åçš„å››å…ƒæ•°
        w, x, y, z = self._check_numerical_stability(w, 'quat_w'), \
                     self._check_numerical_stability(x, 'quat_x'), \
                     self._check_numerical_stability(y, 'quat_y'), \
                     self._check_numerical_stability(z, 'quat_z')
        
        # è®¡ç®—atan2å‰æ£€æŸ¥è¾“å…¥æ˜¯å¦æœ‰NaN/Inf
        numerator = 2 * (w * z + x * y)
        denominator = 1 - 2 * (y**2 + z**2)
        numerator = self._check_numerical_stability(numerator, 'atan2_numerator')
        denominator = self._check_numerical_stability(denominator, 'atan2_denominator')
        
        yaw = torch.atan2(numerator, denominator)
        
        # æ£€æŸ¥ç»“æœå¹¶ä¿®å¤
        yaw = self._check_numerical_stability(yaw, 'yaw_result')
        
        return yaw

    def compute_orientation(self, pos, target):
        # æ£€æŸ¥è¾“å…¥æ•°å€¼ç¨³å®šæ€§
        pos = self._check_numerical_stability(pos, 'compute_orientation_pos')
        target = self._check_numerical_stability(target, 'compute_orientation_target')
        
        # è®¡ç®—ç›®æ ‡æ–¹å‘
        direction_to_target = target - pos
        direction_to_target = self._check_numerical_stability(direction_to_target, 'direction_to_target')
        
        # é˜²æ­¢é™¤é›¶æˆ–å¼‚å¸¸å€¼
        direction_to_target = torch.clamp(direction_to_target, -1000.0, 1000.0)
        
        yaw_target = torch.atan2(direction_to_target[:, 1], direction_to_target[:, 0])
        yaw_target = self._check_numerical_stability(yaw_target, 'yaw_target')
        
        # å¦‚æœä»æœ‰NaNï¼Œæ›¿æ¢ä¸ºé›¶
        yaw_target = torch.where(torch.isnan(yaw_target) | torch.isinf(yaw_target), 
                                 torch.zeros_like(yaw_target), yaw_target)
        
        qx = torch.zeros_like(yaw_target)
        qy = torch.zeros_like(yaw_target)
        qz = torch.sin(yaw_target / 2)
        qw = torch.cos(yaw_target / 2)
        
        # æ£€æŸ¥å››å…ƒæ•°ç»„ä»¶
        qz = self._check_numerical_stability(qz, 'qz')
        qw = self._check_numerical_stability(qw, 'qw')
        
        quat = torch.stack([qw, qx, qy, qz], dim=1)
        quat = self._check_numerical_stability(quat, 'compute_orientation_quat')
        
        return quat
    

    def get_teacher_action(self):
        poses = self._robot.data.root_state_w[:, :2].cpu().numpy()
        yaws = self.quaternion_to_yaw(self._robot.data.root_state_w[:, 3:7]).cpu().numpy()
        idxs = self._current_wp_idx.cpu().numpy()
        trajs = self._trajectories.detach().cpu().numpy()
        horizon = 10

        # æŠŠ step_dt åŠ åˆ°æ¯ä¸ªargs
        args_list = [
            (poses[i], yaws[i], idxs[i], trajs[i], horizon, self.step_dt)
            for i in range(self.num_envs)
        ]
        with ThreadPoolExecutor() as executor:
            actions = list(executor.map(mpc_worker, args_list))

        return torch.tensor(actions, dtype=torch.float32, device=self.device)
    
    def _pre_physics_step(self, actions: torch.Tensor):
        # 3.1 ç¼“å­˜å½“å‰åŠ¨ä½œ
        # - è®°å½•è¾“å…¥çš„åŠ¨ä½œï¼Œä»¥ä¾¿åç»­ä½¿ç”¨
        # action = self.keyboard.advance()
        # vx, wz = action[0], action[1]
        # self._actions = torch.tensor(np.tile([vx, wz], (self.num_envs, 1)), dtype=torch.float32, device=self.device)
        # v, w = self.mpc.solve(
        #     init_state=(x, y, yaw),
        #     ref_traj=your_traj_np_array  # è½¨è¿¹ä¸º np.array([[x0, y0], [x1, y1], ..., [xN, yN]])
        # )
        #self.teacher_actions = self.get_teacher_action()   # [N,2] tensor
        #
        # ç«‹å³æ£€æŸ¥è¾“å…¥åŠ¨ä½œæ˜¯å¦æœ‰NaN/Infï¼ˆæœ€ä¼˜å…ˆæ£€æŸ¥ï¼Œé˜²æ­¢NaNä»å¤–éƒ¨ä¼ å…¥ï¼‰
        if isinstance(actions, torch.Tensor):
            if torch.isnan(actions).any() or torch.isinf(actions).any():
                print(f"ğŸš¨ ä¸¥é‡è­¦å‘Šï¼šè¾“å…¥åŠ¨ä½œåŒ…å«NaN/Infï¼æ­¥æ•°ï¼š{getattr(self, 'global_step', 0)}")
                print(f"   NaNæ•°é‡: {torch.isnan(actions).sum().item()}, Infæ•°é‡: {torch.isinf(actions).sum().item()}")
                # ç«‹å³ä¿®å¤
                actions = torch.where(torch.isnan(actions) | torch.isinf(actions), 
                                    torch.zeros_like(actions), actions)
        
        # ä½¿ç”¨ç»Ÿä¸€çš„æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
        actions = self._check_numerical_stability(actions, 'action_input')
        
        # åŠ¨ä½œå·²ç»åœ¨æ¨¡å‹å†…éƒ¨é€šè¿‡tanhé™åˆ¶åœ¨[-1, 1]
        # è¿™é‡Œåº”ç”¨ç¼©æ”¾å› å­ï¼Œå°†åŠ¨ä½œæ˜ å°„åˆ°å®é™…é€Ÿåº¦èŒƒå›´
        # ä½¿ç”¨ä¹˜æ³•ç¼©æ”¾ï¼ˆæœ‰æ¢¯åº¦ï¼‰ï¼Œè€Œä¸æ˜¯clampï¼ˆæ— æ¢¯åº¦ï¼‰
        # æ¨¡å‹è¾“å‡ºï¼štanhè¾“å‡º[-1,1] * scale = å®é™…åŠ¨ä½œèŒƒå›´
        max_linear_vel = 0.1  # m/s - å®é™…æœ€å¤§çº¿é€Ÿåº¦
        max_angular_vel = 1.0  # rad/s - å®é™…æœ€å¤§è§’é€Ÿåº¦
        
        # åº”ç”¨ç¼©æ”¾ï¼ˆä¹˜æ³•æ“ä½œæœ‰æ¢¯åº¦ï¼Œå¯ä»¥åå‘ä¼ æ’­åˆ°æ¨¡å‹ï¼‰
        scaled_actions = torch.stack([
            actions[:, 0] * max_linear_vel,   # çº¿é€Ÿåº¦ï¼š[-1,1] * 0.1 = [-0.1, 0.1] m/s
            actions[:, 1] * max_angular_vel   # è§’é€Ÿåº¦ï¼š[-1,1] * 1.0 = [-1.0, 1.0] rad/s
        ], dim=1)
        
        self._actions = scaled_actions
        
        # æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥ï¼ˆä¸é™åˆ¶èŒƒå›´ï¼Œåªæ£€æŸ¥NaN/Infï¼‰
        self._actions = self._check_numerical_stability(self._actions, 'final_actions')

    def adjust_yaw_with_velocity_tensor(self, quat, vx):
        # æå–å››å…ƒæ•°åˆ†é‡
        w, x, y, z = quat[:, 0], quat[:, 1], quat[:, 2], quat[:, 3]
        
        # è®¡ç®—å½“å‰çš„ yaw
        yaw = torch.atan2(2 * (w * z + x * y), 1 - 2 * (y**2 + z**2))
        
        # ä¿®æ­£ yaw
        reversing_mask = vx < 0
        yaw[reversing_mask] = (yaw[reversing_mask] + math.pi) % (2 * math.pi)

        # è®¡ç®—æ–°çš„å››å…ƒæ•°
        half_yaw = yaw / 2
        sin_half_yaw = torch.sin(half_yaw)
        cos_half_yaw = torch.cos(half_yaw)

        # ç›´æ¥ä¿®æ”¹åŸå§‹å››å…ƒæ•°ä¸­çš„ z å’Œ w
        adjusted_quat = quat.clone()
        adjusted_quat[:, 3] = sin_half_yaw
        adjusted_quat[:, 0] = cos_half_yaw

        return adjusted_quat

    # 4. åº”ç”¨åŠ¨ä½œåˆ°ç‰©ç†å¼•æ“
    def _apply_action(self):
        # 4.1 å°†åŠ¨ä½œæ˜ å°„ä¸ºå·¦å³è½®é€Ÿåº¦
        linear_vel, angular_vel = self._actions[:, 0], self._actions[:, 1]
        
        # æ£€æŸ¥åŠ¨ä½œæ•°å€¼ç¨³å®šæ€§
        linear_vel = self._check_numerical_stability(linear_vel, 'action_linear_vel')
        angular_vel = self._check_numerical_stability(angular_vel, 'action_angular_vel')
        
        # ç¡®ä¿åŠ¨ä½œåœ¨åˆç†èŒƒå›´å†…
        linear_vel = torch.clamp(linear_vel, -1.0, 1.0)
        angular_vel = torch.clamp(angular_vel, -2.0, 2.0)
        
        # # 4.2 è®¡ç®—å·¦å³è½®é€Ÿåº¦
        left_wheel_vel = linear_vel - angular_vel * self.cfg.wheel_base / 2
        right_wheel_vel = linear_vel + angular_vel * self.cfg.wheel_base / 2
        
        # # 4.3 è®¾ç½®æœºå™¨äººå…³èŠ‚é€Ÿåº¦ç›®æ ‡
        wheel_radius = 0.0357  # å‡è®¾è½®å­åŠå¾„æ˜¯ 5cm
        # é˜²æ­¢é™¤ä»¥é›¶æˆ–å¾ˆå°çš„å€¼ï¼ˆä½¿ç”¨å¼ é‡æ“ä½œç¡®ä¿å¯¹æ‰€æœ‰ç¯å¢ƒéƒ½å®‰å…¨ï¼‰
        wheel_radius_tensor = torch.tensor(wheel_radius, device=self.device, dtype=torch.float32)
        wheel_radius_tensor = torch.clamp(wheel_radius_tensor, min=1e-6)  # ç¡®ä¿ä¸ä¸ºé›¶
        
        left_wheel_vel = left_wheel_vel / wheel_radius_tensor
        right_wheel_vel = right_wheel_vel / wheel_radius_tensor
        
        # æ£€æŸ¥è®¡ç®—åçš„é€Ÿåº¦æ˜¯å¦æœ‰å¼‚å¸¸å€¼
        left_wheel_vel = self._check_numerical_stability(left_wheel_vel, 'left_wheel_vel')
        right_wheel_vel = self._check_numerical_stability(right_wheel_vel, 'right_wheel_vel')
        
        # é™åˆ¶è½®å­é€Ÿåº¦åœ¨åˆç†èŒƒå›´å†…ï¼ˆå¯¹åº”é€Ÿåº¦é™åˆ¶3.0 rad/sï¼‰
        left_wheel_vel = torch.clamp(left_wheel_vel, -3.0, 3.0)
        right_wheel_vel = torch.clamp(right_wheel_vel, -3.0, 3.0)
        
        # # åªé€‰æ‹©å·¦å³è½®çš„å…³èŠ‚
        #    # è®¾ç½®å…³èŠ‚é€Ÿåº¦ç›®æ ‡
        # zero_joint_vel = torch.zeros_like(left_wheel_vel)
        joint_vels = torch.stack([left_wheel_vel, right_wheel_vel],dim=1)
        
        # æœ€ç»ˆæ£€æŸ¥
        joint_vels = self._check_numerical_stability(joint_vels, 'joint_vels')
        
        # åªè®¾ç½®å·¦å³è½®çš„é€Ÿåº¦
        self._robot.set_joint_velocity_target(joint_vels, joint_ids=self.joint_idx)
        
        # æ›´æ–°ä½ç½®å’Œyawï¼Œå¹¶ç«‹å³æ£€æŸ¥
        self.positions = self._robot.data.root_state_w[:, :2]
        self.positions = self._check_numerical_stability(self.positions, 'positions_after_physics')
        
        self.yaw = self._robot.data.root_state_w[:, 3:7]
        self.yaw = self._check_numerical_stability(self.yaw, 'yaw_after_physics')
        # æ£€æŸ¥positionsæ˜¯å¦æœ‰NaN/Infï¼ˆåœ¨è½¬æ¢ä¸ºtensorå‰ï¼‰
        self.positions = self._check_numerical_stability(self.positions, 'positions_before_tensor_conversion')
        
        positions = torch.tensor([[x, y, 0.5] for x, y in self.positions], device=self.device)
        positions = self._check_numerical_stability(positions, 'positions_tensor')
        
        # æ£€æŸ¥è½¨è¿¹æ•°æ®
        current_traj_indices = self._trajectories[range(self.num_envs), self._current_wp_idx]
        current_traj_indices = self._check_numerical_stability(current_traj_indices, 'current_traj_for_orientation')
        
        self.target_orientations = self.compute_orientation(self.positions, current_traj_indices)
        self.target_orientations = self._check_numerical_stability(self.target_orientations, 'target_orientations')
        
        # è®¡ç®—è§’åº¦å·®
        target_yaw = self.quaternion_to_yaw(self.target_orientations)
        robot_yaw = self.quaternion_to_yaw(self.yaw)
        angle_diff = target_yaw - robot_yaw
        angle_diff = self._check_numerical_stability(angle_diff, 'angle_diff')
        
        self.cos_phi = torch.cos(angle_diff).unsqueeze(1)
        self.sin_phi = torch.sin(angle_diff).unsqueeze(1)
        self.cos_phi = self._check_numerical_stability(self.cos_phi, 'cos_phi')
        self.sin_phi = self._check_numerical_stability(self.sin_phi, 'sin_phi')
        linear_vel = self._robot.data.root_lin_vel_b[:, 0]
        self.arrow_visual.visualize(translations=positions, orientations=self.yaw, marker_indices=torch.zeros(self.num_envs, dtype=torch.int64))
        self.target_arrow_visual.visualize(translations=positions, orientations=self.target_orientations, marker_indices=torch.zeros(self.num_envs, dtype=torch.int64))



    # 5. è·å–è§‚æµ‹æ•°æ®
    def _get_observations(self) -> dict:
        self._previous_actions = self._actions.clone()
        future_len = 4  # å½“å‰ç‚¹ + æœªæ¥3ä¸ªè½¨è¿¹ç‚¹
        traj_points = []
        traj_deltas = []
        traj_len = self._trajectories.shape[1]
        # æ£€æŸ¥positionsæ˜¯å¦æœ‰å¼‚å¸¸å€¼ï¼ˆåœ¨è®¡ç®—è·ç¦»å‰ï¼‰
        self.positions = self._check_numerical_stability(self.positions, 'obs_positions')
        
        next_idx = torch.clamp(self._current_wp_idx + 1, max=traj_len - 1)
        # æ£€æŸ¥è½¨è¿¹æ•°æ®æ˜¯å¦æœ‰å¼‚å¸¸å€¼
        current_traj = self._trajectories[range(self.num_envs), self._current_wp_idx]
        next_traj = self._trajectories[range(self.num_envs), next_idx]
        current_traj = self._check_numerical_stability(current_traj, 'obs_current_traj')
        next_traj = self._check_numerical_stability(next_traj, 'obs_next_traj')
        
        # è®¡ç®—è·ç¦»å‰ç¡®ä¿æ•°å€¼ç¨³å®š
        pos_curr_diff = self.positions - current_traj
        pos_next_diff = self.positions - next_traj
        
        pos_curr_diff = self._check_numerical_stability(pos_curr_diff, 'pos_curr_diff')
        pos_next_diff = self._check_numerical_stability(pos_next_diff, 'pos_next_diff')
        
        # åœ¨è®¡ç®—normå‰æ£€æŸ¥è¾“å…¥æ˜¯å¦æœ‰NaN/Inf
        pos_curr_diff = self._check_numerical_stability(pos_curr_diff, 'pos_curr_diff_before_norm')
        pos_next_diff = self._check_numerical_stability(pos_next_diff, 'pos_next_diff_before_norm')
        
        dist_curr = torch.norm(pos_curr_diff, dim=1)
        dist_next = torch.norm(pos_next_diff, dim=1)
        
        # æ£€æŸ¥è·ç¦»è®¡ç®—æ˜¯å¦æœ‰å¼‚å¸¸
        dist_curr = self._check_numerical_stability(dist_curr, 'dist_curr')
        dist_next = self._check_numerical_stability(dist_next, 'dist_next')
        
        # é™åˆ¶è·ç¦»èŒƒå›´ï¼Œé˜²æ­¢å¼‚å¸¸å€¼
        dist_curr = torch.clamp(dist_curr, 0.0, 1000.0)
        dist_next = torch.clamp(dist_next, 0.0, 1000.0)

        # å¦‚æœç¦»ä¸‹ä¸€ä¸ªæ›´è¿‘ï¼Œå°±æ¨è¿› index
        advance_condition = (dist_next + 0.05 < dist_curr) & (dist_curr < 0.4)

        self._current_wp_idx = torch.where(
            advance_condition,
            torch.clamp(self._current_wp_idx + 1, max=traj_len - 1),
            self._current_wp_idx
        )
        for i in range(future_len):
            idx = torch.clamp(self._current_wp_idx + i, max=self._trajectories.shape[1] - 1)
            point = self._trajectories[torch.arange(self.num_envs), idx]
            # æ£€æŸ¥è½¨è¿¹ç‚¹æ˜¯å¦æœ‰å¼‚å¸¸å€¼
            point = self._check_numerical_stability(point, f'obs_traj_point_{i}')
            point = torch.clamp(point, -1000.0, 1000.0)  # é™åˆ¶è½¨è¿¹ç‚¹èŒƒå›´
            traj_points.append(point)
            if i > 0:
                prev_idx = torch.clamp(self._current_wp_idx + i - 1, max=self._trajectories.shape[1] - 1)
                prev_point = self._trajectories[torch.arange(self.num_envs), prev_idx]
                prev_point = self._check_numerical_stability(prev_point, f'obs_traj_prev_point_{i}')
                delta = point - prev_point
                delta = self._check_numerical_stability(delta, f'obs_traj_delta_{i}')
                traj_deltas.append(delta)
        
        # è½¨è¿¹å·®å€¼ç‰¹å¾ï¼ˆç›¸é‚»è½¨è¿¹ç‚¹ä¹‹é—´çš„ç›¸å¯¹å·®å€¼ï¼Œè¡¨ç¤ºè½¨è¿¹è¶‹åŠ¿ï¼‰
        traj_delta_feats = torch.cat(traj_deltas, dim=-1) # [num_envs, 2 * (future_len - 1)]

        # å½“å‰ç›®æ ‡ç‚¹ç›¸å¯¹äºæœºå™¨äººçš„ä½ç½®ï¼ˆç›®æ ‡ç›¸å¯¹äºæœºå™¨äººçš„æ–¹å‘ï¼‰
        # æ³¨æ„ï¼šåº”è¯¥æ˜¯ target - posï¼Œè¿™æ ·å‘é‡æŒ‡å‘ç›®æ ‡ï¼Œæœºå™¨äººçŸ¥é“ç›®æ ‡åœ¨å“ªä¸ªæ–¹å‘
        current_target = traj_points[0]
        current_target = self._check_numerical_stability(current_target, 'obs_current_target')
        current_pos = self._check_numerical_stability(self.positions, 'obs_current_pos_for_error')
        
        relative_error = current_target - current_pos  # [num_envs, 2] æŒ‡å‘ç›®æ ‡çš„æ–¹å‘
        relative_error = self._check_numerical_stability(relative_error, 'obs_relative_error_calc')
        
        # æœªæ¥ç›®æ ‡ç‚¹ç›¸å¯¹äºå½“å‰ç›®æ ‡ç‚¹çš„ä½ç½®ï¼ˆè½¨è¿¹å‰è¿›æ–¹å‘ï¼‰
        # è¿™æ ·æœºå™¨äººå¯ä»¥çŸ¥é“è½¨è¿¹çš„å»¶ä¼¸æ–¹å‘ï¼Œè€Œä¸ä»…ä»…æ˜¯å½“å‰ç›®æ ‡ç‚¹
        future_targets_relative = []
        for i in range(1, min(future_len, len(traj_points))):
            future_target = traj_points[i]
            future_target = self._check_numerical_stability(future_target, f'obs_future_target_{i}')
            # æœªæ¥ç›®æ ‡ç‚¹ç›¸å¯¹äºå½“å‰ç›®æ ‡ç‚¹çš„ä½ç½®
            future_relative = future_target - current_target
            future_relative = self._check_numerical_stability(future_relative, f'obs_future_relative_{i}')
            future_targets_relative.append(future_relative)
        
        if future_targets_relative:
            future_targets_relative = torch.cat(future_targets_relative, dim=-1)  # [num_envs, 2 * (future_len - 1)]
        else:
            future_targets_relative = torch.zeros(self.num_envs, 0, device=self.device)

        # yaw æ–¹å‘ â†’ cos/sin(yaw)
        # æ£€æŸ¥yawæ•°å€¼ç¨³å®šæ€§
        yaw_check = self._check_numerical_stability(self.yaw, 'obs_yaw_quat')
        yaw_tensor = self.quaternion_to_yaw(yaw_check)
        yaw_tensor = self._check_numerical_stability(yaw_tensor, 'obs_yaw_tensor')
        
        # é™åˆ¶yawè§’åº¦èŒƒå›´
        yaw_tensor = torch.clamp(yaw_tensor, -10.0, 10.0)
        
        cos_yaw = torch.cos(yaw_tensor).unsqueeze(1)
        sin_yaw = torch.sin(yaw_tensor).unsqueeze(1)
        
        # æ£€æŸ¥cos/sinè®¡ç®—ç»“æœ
        cos_yaw = self._check_numerical_stability(cos_yaw, 'obs_cos_yaw_calc')
        sin_yaw = self._check_numerical_stability(sin_yaw, 'obs_sin_yaw_calc')

        # === åˆ†åˆ«æ£€æŸ¥æ¯ä¸ªobsç»„ä»¶çš„æ•°å€¼ç¨³å®šæ€§ ===
        # æ£€æŸ¥å„ä¸ªè¾“å…¥ç»„ä»¶ï¼Œé˜²æ­¢INFä¼ æ’­
        lin_vel = self._robot.data.root_lin_vel_b[:, :2]
        lin_vel = self._check_numerical_stability(lin_vel, 'obs_lin_vel')
        lin_vel = torch.clamp(lin_vel, -100.0, 100.0)  # é™åˆ¶é€Ÿåº¦èŒƒå›´
        
        ang_vel = self._robot.data.root_ang_vel_b[:, 2:]
        ang_vel = self._check_numerical_stability(ang_vel, 'obs_ang_vel')
        ang_vel = torch.clamp(ang_vel, -10.0, 10.0)  # é™åˆ¶è§’é€Ÿåº¦èŒƒå›´
        
        actions = self._check_numerical_stability(self._actions, 'obs_actions')
        prev_actions = self._check_numerical_stability(self._previous_actions, 'obs_prev_actions')
        
        relative_error = self._check_numerical_stability(relative_error, 'obs_relative_error')
        relative_error = torch.clamp(relative_error, -100.0, 100.0)  # é™åˆ¶ä½ç½®è¯¯å·®èŒƒå›´
        
        # ç§»é™¤ç»å¯¹è½¨è¿¹ç‚¹ï¼Œåªä¿ç•™ç›¸å¯¹å·®å€¼
        # traj_feats ä¸å†éœ€è¦ï¼Œå› ä¸ºæœºå™¨äººåªéœ€è¦çŸ¥é“ç›¸å¯¹ä½ç½®
        
        traj_delta_feats = self._check_numerical_stability(traj_delta_feats, 'obs_traj_delta_feats')
        traj_delta_feats = torch.clamp(traj_delta_feats, -100.0, 100.0)  # é™åˆ¶è½¨è¿¹å·®å€¼èŒƒå›´
        
        # æœªæ¥ç›®æ ‡ç‚¹ç›¸å¯¹äºå½“å‰ç›®æ ‡ç‚¹çš„ä½ç½®
        if future_targets_relative.numel() > 0:
            future_targets_relative = self._check_numerical_stability(future_targets_relative, 'obs_future_targets_relative')
            future_targets_relative = torch.clamp(future_targets_relative, -100.0, 100.0)  # é™åˆ¶èŒƒå›´
        else:
            future_targets_relative = torch.zeros(self.num_envs, 0, device=self.device)
        
        cos_yaw = self._check_numerical_stability(cos_yaw, 'obs_cos_yaw')
        sin_yaw = self._check_numerical_stability(sin_yaw, 'obs_sin_yaw')
        # coså’Œsinç†è®ºä¸Šåº”è¯¥åœ¨[-1,1]èŒƒå›´å†…ï¼Œä½†ä¸ºäº†å®‰å…¨ä¹Ÿclampä¸€ä¸‹
        cos_yaw = torch.clamp(cos_yaw, -1.0, 1.0)
        sin_yaw = torch.clamp(sin_yaw, -1.0, 1.0)

        # === è§‚æµ‹å½’ä¸€åŒ–ï¼šå°†å„ä¸ªç»„ä»¶ç¼©æ”¾åˆ°ç›¸è¿‘çš„èŒƒå›´ï¼Œæé«˜å½’ä¸€åŒ–æ•ˆæœ ===
        # 1. çº¿é€Ÿåº¦ï¼šå½’ä¸€åŒ–åˆ°[-1, 1]èŒƒå›´ï¼ˆå‡è®¾æœ€å¤§é€Ÿåº¦0.1 m/sï¼‰
        lin_vel_normalized = lin_vel / 0.1  # å½’ä¸€åŒ–ï¼š[-0.1, 0.1] -> [-1, 1]
        lin_vel_normalized = torch.clamp(lin_vel_normalized, -1.0, 1.0)
        
        # 2. è§’é€Ÿåº¦ï¼šå½’ä¸€åŒ–åˆ°[-1, 1]èŒƒå›´ï¼ˆå‡è®¾æœ€å¤§è§’é€Ÿåº¦1.0 rad/sï¼‰
        ang_vel_normalized = ang_vel / 1.0  # å½’ä¸€åŒ–ï¼š[-1, 1] -> [-1, 1]ï¼ˆå·²ç»æ˜¯å½’ä¸€åŒ–çš„ï¼‰
        ang_vel_normalized = torch.clamp(ang_vel_normalized, -1.0, 1.0)
        
        # 3. åŠ¨ä½œï¼šå·²ç»æ˜¯å½’ä¸€åŒ–çš„ï¼ˆçº¿é€Ÿåº¦çº¦[-0.1, 0.1]ï¼Œè§’é€Ÿåº¦çº¦[-1, 1]ï¼‰
        actions_normalized = torch.stack([
            actions[:, 0] / 0.1,   # çº¿é€Ÿåº¦å½’ä¸€åŒ–ï¼š[-0.1, 0.1] -> [-1, 1]
            actions[:, 1] / 1.0    # è§’é€Ÿåº¦å½’ä¸€åŒ–ï¼š[-1, 1] -> [-1, 1]
        ], dim=1)
        actions_normalized = torch.clamp(actions_normalized, -1.0, 1.0)
        
        prev_actions_normalized = torch.stack([
            prev_actions[:, 0] / 0.1,   # çº¿é€Ÿåº¦å½’ä¸€åŒ–
            prev_actions[:, 1] / 1.0     # è§’é€Ÿåº¦å½’ä¸€åŒ–
        ], dim=1)
        prev_actions_normalized = torch.clamp(prev_actions_normalized, -1.0, 1.0)
        
        # 4. ç›¸å¯¹è¯¯å·®ï¼šå½’ä¸€åŒ–åˆ°[-1, 1]èŒƒå›´ï¼ˆå‡è®¾æœ€å¤§è¯¯å·®10ç±³ï¼‰
        relative_error_normalized = relative_error / 10.0  # å½’ä¸€åŒ–ï¼š[-10, 10] -> [-1, 1]
        relative_error_normalized = torch.clamp(relative_error_normalized, -1.0, 1.0)
        
        # 5. è½¨è¿¹å·®å€¼ï¼šå½’ä¸€åŒ–åˆ°[-1, 1]èŒƒå›´ï¼ˆå‡è®¾æœ€å¤§å·®å€¼1ç±³ï¼‰
        traj_delta_feats_normalized = traj_delta_feats / 1.0  # å½’ä¸€åŒ–ï¼š[-1, 1] -> [-1, 1]
        traj_delta_feats_normalized = torch.clamp(traj_delta_feats_normalized, -1.0, 1.0)
        
        # 6. æœªæ¥ç›®æ ‡ç‚¹ç›¸å¯¹ä½ç½®ï¼šå½’ä¸€åŒ–åˆ°[-1, 1]èŒƒå›´ï¼ˆå‡è®¾æœ€å¤§å·®å€¼1ç±³ï¼‰
        if future_targets_relative.numel() > 0:
            future_targets_relative_normalized = future_targets_relative / 1.0  # å½’ä¸€åŒ–ï¼š[-1, 1] -> [-1, 1]
            future_targets_relative_normalized = torch.clamp(future_targets_relative_normalized, -1.0, 1.0)
        else:
            future_targets_relative_normalized = torch.zeros(self.num_envs, 0, device=self.device)
        
        # 7. cos/sinï¼šå·²ç»æ˜¯[-1, 1]èŒƒå›´ï¼Œæ— éœ€å½’ä¸€åŒ–

        obs = torch.cat([
            lin_vel_normalized,                    # çº¿é€Ÿåº¦ (2,) - å½’ä¸€åŒ–åˆ°[-1, 1]
            ang_vel_normalized,                   # è§’é€Ÿåº¦ (1,) - å½’ä¸€åŒ–åˆ°[-1, 1]
            actions_normalized,                   # å½“å‰åŠ¨ä½œ (2,) - å½’ä¸€åŒ–åˆ°[-1, 1]
            prev_actions_normalized,              # ä¸Šä¸€æ­¥åŠ¨ä½œ (2,) - å½’ä¸€åŒ–åˆ°[-1, 1]
            relative_error_normalized,            # å½“å‰ç›®æ ‡ç›¸å¯¹ä½ç½® (2,) - å½’ä¸€åŒ–åˆ°[-1, 1]
            traj_delta_feats_normalized,          # è½¨è¿¹è¶‹åŠ¿ï¼ˆç›¸é‚»ç‚¹å·®å€¼ï¼‰(2Ã—3) - å½’ä¸€åŒ–åˆ°[-1, 1]
            future_targets_relative_normalized,    # æœªæ¥ç›®æ ‡ç›¸å¯¹ä½ç½® (2Ã—3) - å½’ä¸€åŒ–åˆ°[-1, 1]
            cos_yaw, sin_yaw                      # å§¿æ€ä¿¡æ¯ (2,) - å·²ç»æ˜¯[-1, 1]
        ], dim=-1)
        
        # ä½¿ç”¨ç»Ÿä¸€çš„æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥ï¼ˆæœ€ç»ˆæ£€æŸ¥ï¼‰
        obs = self._check_numerical_stability(obs, 'obs')
        
        # å½’ä¸€åŒ–åçš„è§‚æµ‹å€¼åº”è¯¥åœ¨[-1, 1]èŒƒå›´å†…ï¼Œä½†ä¸ºäº†å®‰å…¨ä¹Ÿclampä¸€ä¸‹
        obs = torch.clamp(obs, -1.0, 1.0)  # é™åˆ¶åœ¨[-1, 1]èŒƒå›´å†…
        
        # å¼ºåˆ¶æ›¿æ¢æ‰€æœ‰NaNå’ŒInfï¼ˆåŒé‡ä¿é™©ï¼‰
        obs = torch.where(torch.isnan(obs) | torch.isinf(obs), torch.zeros_like(obs), obs)
        
        # é¢å¤–çš„å®‰å…¨æ£€æŸ¥
        if torch.isnan(obs).any() or torch.isinf(obs).any():
            print(f"ä¸¥é‡è­¦å‘Šï¼šå½’ä¸€åŒ–åçš„è§‚æµ‹æ•°æ®ä¸­ä»æœ‰NaN/Infï¼Œæ­¥æ•°ï¼š{self.global_step}")
            print(f"å°è¯•å•ç‹¬æ£€æŸ¥å„ä¸ªç»„ä»¶...")
            components = {
                'lin_vel_normalized': lin_vel_normalized,
                'ang_vel_normalized': ang_vel_normalized,
                'actions_normalized': actions_normalized,
                'prev_actions_normalized': prev_actions_normalized,
                'relative_error_normalized': relative_error_normalized,
                'traj_delta_feats_normalized': traj_delta_feats_normalized,
                'future_targets_relative_normalized': future_targets_relative_normalized if future_targets_relative_normalized.numel() > 0 else torch.zeros(1, 0, device=self.device),
                'cos_yaw': cos_yaw,
                'sin_yaw': sin_yaw
            }
            for name, comp in components.items():
                if torch.isnan(comp).any() or torch.isinf(comp).any():
                    print(f"  âš ï¸  å‘ç° {name} åŒ…å« NaN/Inf!")
            # å¦‚æœä»æœ‰NaN/Infï¼Œå¼ºåˆ¶æ›¿æ¢ä¸ºé›¶
            obs = torch.where(torch.isnan(obs) | torch.isinf(obs), torch.zeros_like(obs), obs)
        
        # æœ€ç»ˆéªŒè¯ï¼šç¡®ä¿æ²¡æœ‰ä»»ä½•NaN/Infï¼ˆå¦‚æœä»æœ‰ï¼Œå¼ºåˆ¶æ›¿æ¢ä¸ºé›¶ï¼‰
        if torch.isnan(obs).any() or torch.isinf(obs).any():
            print(f"âš ï¸  æœ€ç»ˆæ¸…ç†ï¼šå¼ºåˆ¶æ›¿æ¢å½’ä¸€åŒ–è§‚æµ‹ä¸­å‰©ä½™çš„NaN/Infï¼Œæ­¥æ•°ï¼š{self.global_step}")
            obs = torch.where(torch.isnan(obs) | torch.isinf(obs), torch.zeros_like(obs), obs)
        
        # æœ€ç»ˆèŒƒå›´é™åˆ¶ï¼šç¡®ä¿å½’ä¸€åŒ–åçš„è§‚æµ‹å€¼åœ¨[-1, 1]èŒƒå›´å†…
        obs = torch.clamp(obs, -1.0, 1.0)  # å½’ä¸€åŒ–åçš„è§‚æµ‹åº”è¯¥åœ¨[-1, 1]èŒƒå›´å†…
        
        # æœ€åä¸€æ¬¡å¼ºåˆ¶NaN/Infæ¸…ç†
        obs = torch.where(torch.isnan(obs) | torch.isinf(obs), torch.zeros_like(obs), obs)
        
        return {"policy": obs}

    # 6. è®¡ç®—å¥–åŠ±
    def _get_rewards(self) -> torch.Tensor:
        # æ€§èƒ½ç›‘æ§å¼€å§‹
        step_start_time = time.time()
        self.global_step += 1

        # === è¯¾ç¨‹å­¦ä¹ æ›´æ–° ===
        if self.curriculum_enabled:
            self._update_curriculum_stage()

        # === æ£€æµ‹ç›®æ ‡ç‚¹åˆ‡æ¢ ===
        target_switched = self._current_wp_idx != self._prev_wp_idx
        self._target_switch_detected = target_switched
        self._prev_wp_idx = self._current_wp_idx.clone()

        # === å½“å‰è½¨è¿¹æ®µ ===
        id = torch.clamp(self._current_wp_idx, max=self._trajectories.shape[1] - 2)
        current_target = self._trajectories[torch.arange(self.num_envs), id]
        next_target = self._trajectories[torch.arange(self.num_envs), id + 1]
        
        # === å‘é‡å®šä¹‰ ===
        pos = self.positions
        vel = self._robot.data.root_lin_vel_w[:, :2]
        ab = next_target - current_target  # è·¯å¾„æ–¹å‘å‘é‡
        pa = current_target - pos  # ä»ä½ç½®æŒ‡å‘ç›®æ ‡çš„æ–¹å‘ï¼ˆä¿®æ­£ï¼šåº”è¯¥æ˜¯ target - posï¼ŒæŒ‡å‘ç›®æ ‡ï¼‰
        # è®¡ç®—è·¯å¾„æ–¹å‘å‘é‡çš„å½’ä¸€åŒ–ï¼Œé˜²æ­¢é™¤é›¶
        # å…ˆæ£€æŸ¥è¾“å…¥æ˜¯å¦æœ‰NaN/Inf
        ab = self._check_numerical_stability(ab, 'ab_before_norm')
        ab_norm = torch.norm(ab, dim=1, keepdim=True)
        ab_norm = self._check_numerical_stability(ab_norm, 'ab_norm_before_clamp')
        ab_norm = torch.clamp(ab_norm, min=1e-6)  # ç¡®ä¿ä¸ä¸ºé›¶
        ab_unit = ab / ab_norm
        ab_unit = self._check_numerical_stability(ab_unit, 'ab_unit')

        # === æŠ•å½±ç‚¹ï¼ˆè·¯å¾„ä¸Šçš„æœ€è¿‘ç‚¹ï¼‰ ===
        # æ³¨æ„ï¼šap ç”¨äºæŠ•å½±è®¡ç®—ï¼ˆä»ç›®æ ‡åˆ°ä½ç½®ï¼‰ï¼Œä½†ç”¨äºæ–¹å‘è®¡ç®—åº”è¯¥ç”¨ pa
        ap = pos - current_target  # ä»ç›®æ ‡åˆ°ä½ç½®ï¼ˆç”¨äºè·ç¦»è®¡ç®—ï¼‰
        t = torch.clamp(torch.sum(ap * ab, dim=1) / (torch.sum(ab * ab, dim=1) + 1e-6), 0.0, 1.0).unsqueeze(1)
        proj = current_target + t * ab

        # === è·ç¦»è¯¯å·® ===
        # åœ¨è®¡ç®—normå‰æ£€æŸ¥è¾“å…¥
        pos_proj_diff = pos - proj
        pos_proj_diff = self._check_numerical_stability(pos_proj_diff, 'pos_proj_diff_before_norm')
        lateral_error = torch.norm(pos_proj_diff, dim=1)
        lateral_error = self._check_numerical_stability(lateral_error, 'lateral_error')
        
        # æ£€æŸ¥paå¹¶è®¡ç®—è·ç¦»
        pa = self._check_numerical_stability(pa, 'pa_before_norm')
        dist_to_target = torch.norm(pa, dim=1)  # ä½¿ç”¨æŒ‡å‘ç›®æ ‡çš„æ–¹å‘è®¡ç®—è·ç¦»
        dist_to_target = self._check_numerical_stability(dist_to_target, 'dist_to_target')
        self.dist_to_target = dist_to_target  # ç”¨äº bias è®¡ç®—

        # === è·¯å¾„æ¨è¿›å¥–åŠ±ï¼ˆè·¯å¾„åˆ‡å‘é€Ÿåº¦ï¼‰ ===
        forward_vector = self.quaternion_to_yaw(self.yaw)
        heading = torch.stack([torch.cos(forward_vector), torch.sin(forward_vector)], dim=1)  # shape: [N, 2]
        v_forward = torch.sum(vel * ab_unit, dim=1)
        alignment = torch.sum(heading * ab_unit, dim=1)  # cos(heading_angle - path_angle)
        # ä¿®æ­£ï¼šåªæœ‰å½“é€Ÿåº¦æ–¹å‘å’Œè·¯å¾„æ–¹å‘ä¸€è‡´ï¼ˆalignment > 0ï¼‰ä¸”å‘å‰ç§»åŠ¨ï¼ˆv_forward > 0ï¼‰æ—¶æ‰ç»™å¥–åŠ±
        progress_reward = torch.tanh(v_forward) * torch.clamp(alignment, min=0.0)  # åªå¥–åŠ±æœå‘æ­£ç¡®æ–¹å‘çš„ç§»åŠ¨

        # === åˆ°è¾¾å¥–åŠ± ===
        done_mask = (self._current_wp_idx >= self._trajectories.shape[1] - 1) & (dist_to_target < 0.2)
        bias = torch.zeros_like(dist_to_target)
        mask = (dist_to_target >= 0.2) & (dist_to_target < 0.5)
        bias[mask] = 0.0
        bias[done_mask] = 0.0  # ç»ˆç‚¹ bonus

        # === æœå‘å¥–åŠ±ï¼ˆæ”¹è¿›ç‰ˆ - å¹³æ»‘å¤„ç†ï¼‰ ===
        # ä¿®æ­£ï¼štarget_heading åº”è¯¥æ˜¯æœå‘ç›®æ ‡çš„æ–¹å‘ï¼Œå³ pa çš„è§’åº¦ï¼ˆtarget - posï¼‰
        target_heading = torch.atan2(pa[:, 1], pa[:, 0])  # ä»ä½ç½®æŒ‡å‘ç›®æ ‡çš„æ–¹å‘
        next_heading = torch.atan2(ab[:, 1], ab[:, 0])  # è·¯å¾„æ–¹å‘
        heading_error = forward_vector - target_heading  # æœºå™¨äººæœå‘ä¸ç›®æ ‡æ–¹å‘çš„è¯¯å·®
        
        # å°†è§’åº¦è¯¯å·®æ ‡å‡†åŒ–åˆ° [-Ï€, Ï€]
        heading_error = torch.atan2(torch.sin(heading_error), torch.cos(heading_error))
        self.headerror = heading_error

        # ä½¿ç”¨é«˜æ–¯å‡½æ•°æ›¿ä»£çº¿æ€§æƒ©ç½šï¼Œæ›´å¹³æ»‘
        # æ³¨æ„ï¼šheading_error è¶Šå°ï¼ˆæ¥è¿‘0ï¼‰ï¼Œå¥–åŠ±è¶Šå¤§ï¼Œé¼“åŠ±æœºå™¨äººæœå‘ç›®æ ‡
        direction_reward = torch.exp(-heading_error.abs() * 2.0)  # é«˜æ–¯å½¢å¼ï¼Œæ›´å¹³æ»‘
        
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯ï¼šè®°å½•æ–¹å‘ç›¸å…³ä¿¡æ¯ï¼ˆæ¯100æ­¥è®°å½•ä¸€æ¬¡ï¼‰
        if self.global_step % 100 == 0 and hasattr(self, 'writer'):
            self._safe_add_scalar("Debug/Target_Heading_Deg", torch.rad2deg(target_heading).mean(), self.global_step)
            self._safe_add_scalar("Debug/Robot_Heading_Deg", torch.rad2deg(forward_vector).mean(), self.global_step)
            self._safe_add_scalar("Debug/Heading_Error_Deg", torch.rad2deg(heading_error.abs()).mean(), self.global_step)
            self._safe_add_scalar("Debug/Progress_Reward", progress_reward.mean(), self.global_step)
            self._safe_add_scalar("Debug/V_Forward", v_forward.mean(), self.global_step)
            self._safe_add_scalar("Debug/Alignment", alignment.mean(), self.global_step)
        

        # === åŠ¨ä½œæƒ©ç½š ===
        action_rate = torch.sum(torch.square(self._actions - self._previous_actions), dim=1)
        action_magnitude = torch.norm(self._actions, dim=1)
        action_rate_penalty = -torch.tanh(action_rate)
        action_mag_penalty = -torch.tanh(action_magnitude)

        # === æ•™å¸ˆå¥–åŠ± ===
        imitate_loss = torch.sum((self._actions - self._actions) ** 2, dim=1)
        imitate_reward = -imitate_loss
        # === åˆå¹¶å¥–åŠ± ===
        rewards = {
            "progress_reward": progress_reward * self.cfg.traj_track_scale * self.step_dt,
            "lateral_penalty": -lateral_error * self.cfg.lateral_error_scale * self.step_dt,  # æ·»åŠ  config é¡¹
            "direction_reward": direction_reward * self.cfg.direction_scale * self.step_dt,
            "goal_bias": bias * self.cfg.traj_done_bonus,
            "action_rate_penalty": action_rate_penalty * self.cfg.action_rate_reward_scale * self.step_dt,
            "action_mag_penalty": action_mag_penalty * self.cfg.action_magnitude_scale * self.step_dt,
            "imitation_reward": imitate_reward * self.cfg.imitation_scale * self.step_dt
        }
        
        # === åº”ç”¨å¥–åŠ±å¹³æ»‘å¤„ç† ===
        rewards = self._apply_reward_smoothing(rewards, target_switched)
        
        # æ£€æŸ¥æ¯ä¸ªå¥–åŠ±ç»„ä»¶
        for key, value in rewards.items():
            rewards[key] = self._check_numerical_stability(value, f'reward_{key}')
        
        reward = torch.sum(torch.stack(list(rewards.values())), dim=0)
        
        # ä½¿ç”¨ç»Ÿä¸€çš„æ•°å€¼ç¨³å®šæ€§æ£€æŸ¥
        reward = self._check_numerical_stability(reward, 'reward')
        reward = torch.clamp(reward, -100.0, 100.0)
        
        # é¢å¤–çš„å®‰å…¨æ£€æŸ¥
        if torch.isnan(reward).any() or torch.isinf(reward).any():
            print(f"ä¸¥é‡è­¦å‘Šï¼šå¥–åŠ±ä¸­ä»æœ‰NaN/Infï¼Œæ­¥æ•°ï¼š{self.global_step}")
            reward = torch.zeros_like(reward)
        # === è¯¦ç»†æŒ‡æ ‡è®¡ç®— ===
        # è®¡ç®—è·ç¦»æŒ‡æ ‡
        current_pos = self._robot.data.root_state_w[:, :2]
        # è®¡ç®—è·ç¦»å‰æ£€æŸ¥
        pos_diff = current_pos - self.last_pos
        pos_diff = self._check_numerical_stability(pos_diff, 'pos_diff_for_distance')
        distance_traveled = torch.norm(pos_diff, dim=1)
        distance_traveled = self._check_numerical_stability(distance_traveled, 'distance_traveled')
        self._episode_metrics["total_distance"] += distance_traveled
        
        # è®¡ç®—é€Ÿåº¦æŒ‡æ ‡
        # è®¡ç®—é€Ÿåº¦å‰æ£€æŸ¥
        vel_data = self._robot.data.root_state_w[:, 7:9]
        vel_data = self._check_numerical_stability(vel_data, 'vel_data_before_norm')
        current_vel = torch.norm(vel_data, dim=1)
        current_vel = self._check_numerical_stability(current_vel, 'current_vel')
        # é˜²æ­¢é™¤ä»¥é›¶ï¼šå¦‚æœglobal_stepä¸º0ï¼Œç›´æ¥ä½¿ç”¨current_vel
        divisor = torch.clamp(torch.tensor(self.global_step + 1, device=self.device, dtype=torch.float32), min=1.0)
        self._episode_metrics["avg_speed"] = (self._episode_metrics["avg_speed"] * self.global_step + current_vel) / divisor
        
        # è®¡ç®—ä¾§å‘è¯¯å·®
        lateral_error_abs = lateral_error.abs()
        self._episode_metrics["max_lateral_error"] = torch.max(self._episode_metrics["max_lateral_error"], lateral_error_abs)
        
        # è®¡ç®—æœ€ç»ˆè·ç¦»
        self._episode_metrics["final_distance"] = dist_to_target
        
        # æ›´æ–°ä½ç½®è®°å½•
        self.last_pos = current_pos.clone()
        
        # === æ—¥å¿—è®°å½• ===
        # è®°å½•å¥–åŠ±æŒ‡æ ‡ï¼ˆä½¿ç”¨å®‰å…¨æ–¹æ³•é˜²æ­¢NaN/Infï¼‰
        for key, value in rewards.items():
            self._episode_sums[key] = self._episode_sums.get(key, torch.zeros_like(value)) + value
            self._safe_add_scalar(f"Reward/{key}", value.mean(), self.global_step)

        self._safe_add_scalar("Reward/Total", reward.mean(), self.global_step)
        
        # è®°å½•ç¯å¢ƒæŒ‡æ ‡
        self._safe_add_scalar("Environment/Distance_to_Target", dist_to_target.mean(), self.global_step)
        self._safe_add_scalar("Environment/Lateral_Error", lateral_error.abs().mean(), self.global_step)
        self._safe_add_scalar("Environment/Heading_Error", heading_error.abs().mean(), self.global_step)
        self._safe_add_scalar("Environment/Robot_Speed", current_vel.mean(), self.global_step)
        self._safe_add_scalar("Environment/Action_Magnitude", action_magnitude.mean(), self.global_step)
        self._safe_add_scalar("Environment/Action_Rate", action_rate.mean(), self.global_step)
        
        # è®°å½•å¹³æ»‘ç›¸å…³æŒ‡æ ‡
        self._safe_add_scalar("Smoothing/Target_Switch_Count", target_switched.sum(), self.global_step)
        self._safe_add_scalar("Smoothing/Current_WP_Index", self._current_wp_idx.float().mean(), self.global_step)
        
        # è®°å½•æ•°å€¼ç¨³å®šæ€§æŒ‡æ ‡
        for key, count in self.nan_inf_count.items():
            self._safe_add_scalar(f"Debug/{key}_nan_inf_count", count, self.global_step)
        
        # è®°å½•è¯¾ç¨‹å­¦ä¹ æŒ‡æ ‡
        if self.curriculum_enabled:
            self._safe_add_scalar("Curriculum/Current_Stage", self.curriculum_stage, self.global_step)
            self._safe_add_scalar("Curriculum/Episode_Count", self.episode_count, self.global_step)
            self._safe_add_scalar("Curriculum/Num_Waypoints", self.cfg.num_waypoints, self.global_step)
            self._safe_add_scalar("Curriculum/Num_Interp", self.cfg.num_interp, self.global_step)
            self._safe_add_scalar("Curriculum/Step_Size", self.cfg.step_size, self.global_step)
            self._safe_add_scalar("Curriculum/Episode_Length", self.cfg.episode_length_s, self.global_step)
        
        # è®°å½•æ€§èƒ½æŒ‡æ ‡
        self._safe_add_scalar("Performance/Episode_Length", self.global_step, self.global_step)
        self._safe_add_scalar("Performance/Total_Distance", self._episode_metrics["total_distance"].mean(), self.global_step)
        self._safe_add_scalar("Performance/Average_Speed", self._episode_metrics["avg_speed"].mean(), self.global_step)
        self._safe_add_scalar("Performance/Max_Lateral_Error", self._episode_metrics["max_lateral_error"].mean(), self.global_step)
        
        # æ€§èƒ½ç»Ÿè®¡
        step_time = time.time() - step_start_time
        self._performance_stats["step_time"] = step_time
        self._performance_stats["fps"] = 1.0 / step_time if step_time > 0 else 0.0
        
        # è®°å½•æ€§èƒ½æŒ‡æ ‡åˆ° TensorBoard
        self._safe_add_scalar("Performance/Step_Time", step_time, self.global_step)
        self._safe_add_scalar("Performance/FPS", self._performance_stats["fps"], self.global_step)
        
        # æ¯100æ­¥è®°å½•ä¸€æ¬¡è¯¦ç»†ç»Ÿè®¡
        if self.global_step % 100 == 0:
            elapsed_time = time.time() - self.begin_time
            self._safe_add_scalar("Training/Elapsed_Time", elapsed_time, self.global_step)
            steps_per_second = self.global_step / elapsed_time if elapsed_time > 0 else 0.0
            self._safe_add_scalar("Training/Steps_Per_Second", steps_per_second, self.global_step)

        return reward
    # 7. åˆ¤æ–­å›åˆç»“æŸ
    def _get_dones(self) -> tuple[torch.Tensor, torch.Tensor]:
        # 7.1 åˆ¤æ–­æ˜¯å¦è¾¾åˆ°æœ€å¤§å›åˆæ­¥æ•°
        time_out = self.episode_length_buf >= self.max_episode_length - 1
        reached_target = torch.zeros_like(time_out, dtype=torch.bool)
        if self.dist_to_target is not None:
            reached_target = self.dist_to_target < 0.2
            self._current_wp_idx[reached_target] += 1
        finished_traj = self._current_wp_idx >= self._trajectories.shape[1]
        self.finished_mask = finished_traj
        self.count += sum(finished_traj)
        
        # è®°å½•å›åˆç»“æŸç»Ÿè®¡
        episode_dones = finished_traj | time_out
        if episode_dones.any():
            self._log_episode_statistics(episode_dones)
            
            # æ›´æ–°è¯¾ç¨‹å­¦ä¹ ç»Ÿè®¡
            if self.curriculum_enabled:
                for i, done in enumerate(episode_dones):
                    if done:
                        success = finished_traj[i].item()  # æ˜¯å¦æˆåŠŸå®Œæˆè½¨è¿¹
                        self._update_curriculum_stats(success)
        
        self.last_pos = self.positions
        return finished_traj, time_out

    def _log_episode_statistics(self, episode_dones: torch.Tensor):
        """è®°å½•å›åˆç»“æŸæ—¶çš„ç»Ÿè®¡ä¿¡æ¯"""
        if not episode_dones.any():
            return
            
        # è®¡ç®—æˆåŠŸç‡
        success_rate = (self._current_wp_idx >= self._trajectories.shape[1]).float().mean().item()
        
        # è®°å½•å›åˆç»Ÿè®¡
        for i, done in enumerate(episode_dones):
            if done:
                # è®°å½•æ¯ä¸ªç¯å¢ƒçš„å›åˆç»Ÿè®¡
                episode_reward = sum(self._episode_sums[key][i].item() for key in self._episode_sums.keys())
                episode_length = self.episode_length_buf[i].item()
                
                # æ›´æ–°è®­ç»ƒç»Ÿè®¡
                self._training_stats["total_episodes"] += 1
                self._training_stats["best_reward"] = max(self._training_stats["best_reward"], episode_reward)
                # é˜²æ­¢é™¤ä»¥é›¶ï¼šç¡®ä¿total_episodes > 0
                total_eps = max(self._training_stats["total_episodes"], 1)
                self._training_stats["avg_reward"] = (
                    (self._training_stats["avg_reward"] * (total_eps - 1) + episode_reward) 
                    / total_eps
                )
                
                # è®°å½•åˆ° TensorBoardï¼ˆä½¿ç”¨å®‰å…¨æ–¹æ³•é˜²æ­¢NaN/Infï¼‰
                self._safe_add_scalar("Episode/Episode_Reward", episode_reward, self._training_stats["total_episodes"])
                self._safe_add_scalar("Episode/Episode_Length", episode_length, self._training_stats["total_episodes"])
                self._safe_add_scalar("Episode/Success_Rate", success_rate, self._training_stats["total_episodes"])
                self._safe_add_scalar("Episode/Total_Distance", self._episode_metrics["total_distance"][i], self._training_stats["total_episodes"])
                self._safe_add_scalar("Episode/Final_Distance", self._episode_metrics["final_distance"][i], self._training_stats["total_episodes"])
                self._safe_add_scalar("Episode/Max_Lateral_Error", self._episode_metrics["max_lateral_error"][i], self._training_stats["total_episodes"])
                
                # è®°å½•å„å¥–åŠ±åˆ†é‡
                for key in self._episode_sums.keys():
                    self._safe_add_scalar(f"Episode_Reward/{key}", self._episode_sums[key][i], self._training_stats["total_episodes"])
        
        # è®°å½•å…¨å±€ç»Ÿè®¡
        self._safe_add_scalar("Training/Best_Reward", self._training_stats["best_reward"], self.global_step)
        self._safe_add_scalar("Training/Average_Reward", self._training_stats["avg_reward"], self.global_step)
        self._safe_add_scalar("Training/Total_Episodes", self._training_stats["total_episodes"], self.global_step)
        
        # é‡ç½®å›åˆæŒ‡æ ‡
        for key in self._episode_sums.keys():
            self._episode_sums[key][episode_dones] = 0.0
        for key in self._episode_metrics.keys():
            self._episode_metrics[key][episode_dones] = 0.0

    # 8. ç¯å¢ƒé‡ç½®
    def draw_spline(self, traj_points, color=(0.0, 1.0, 0.0), thickness=1.0):
        """
        ä½¿ç”¨ debug_draw ç»˜åˆ¶ spline æ›²çº¿
        traj_points: torch.Tensor (N, 2) or (N, 3)
        """
        import carb
        if traj_points.shape[1] == 2:
            z = torch.full((traj_points.shape[0], 1), 0.05, device=traj_points.device)
            traj_points = torch.cat([traj_points, z], dim=1)

        # è½¬æ¢ä¸º List[carb.Float3]
        points = [carb.Float3(*p.cpu().tolist()) for p in traj_points]

        self.debug_draw.draw_lines_spline(points, carb.ColorRgba(*color, 1.0), thickness, False)

    def generate_random_walk_trajectory(self,start_pos, num_points=2, step_size=1.0, seed=42, num_interp=1):
        torch.manual_seed(seed)
        traj = [start_pos]
        for _ in range(num_points - 1):
            angle = torch.rand(1) * 2 * math.pi
            direction = torch.tensor([torch.cos(angle), torch.sin(angle)], device=self.device)
            new_point = traj[-1] + direction * step_size
            traj.append(new_point)
        points = torch.stack(traj).cpu().numpy()
        t = np.linspace(0, 1, len(points))
        cs_x = CubicSpline(t, points[:, 0])
        cs_y = CubicSpline(t, points[:, 1])
        
        t_new = np.linspace(0, 1, len(points) * num_interp)
        x_new = cs_x(t_new)
        y_new = cs_y(t_new)
        smoothed = np.stack([x_new, y_new], axis=1)
        
        # æ£€æŸ¥ç”Ÿæˆçš„è½¨è¿¹æ˜¯å¦æœ‰NaNæˆ–Inf
        if np.any(np.isnan(smoothed)) or np.any(np.isinf(smoothed)):
            print(f"è­¦å‘Šï¼šè½¨è¿¹ç”Ÿæˆä¸­å‡ºç°NaN/Infï¼Œä½¿ç”¨ç®€å•ç›´çº¿è½¨è¿¹æ›¿ä»£")
            # ç”Ÿæˆç®€å•çš„ç›´çº¿è½¨è¿¹ä½œä¸ºå¤‡ç”¨
            simple_traj = np.linspace(start_pos.cpu().numpy(), start_pos.cpu().numpy() + [step_size, 0], num_points * num_interp)
            smoothed = simple_traj

        traj_tensor = torch.tensor(smoothed, dtype=torch.float32, device=self.device)
        return self._check_numerical_stability(traj_tensor, 'trajectory')



    def _reset_idx(self, env_ids: torch.Tensor | None):
        # 8.1 è·å–éœ€è¦é‡ç½®çš„ç¯å¢ƒ ID
        if env_ids is None or len(env_ids) == self.num_envs:
            env_ids = self._robot._ALL_INDICES
        if self.finished_mask is None:
            self.finished_mask = torch.zeros(self.num_envs, dtype=torch.bool, device=env_ids.device)
        # 8.2 é‡ç½®æœºå™¨äººçŠ¶æ€
        self._robot.reset(env_ids)
        # 8.3 é‡ç½®åŸºç¡€ç¯å¢ƒçŠ¶æ€
        super()._reset_idx(env_ids)
        
        # 8.4 é‡ç½®å¥–åŠ±å¹³æ»‘çŠ¶æ€
        if env_ids is not None:
            self._prev_wp_idx[env_ids] = 0
            self._target_switch_detected[env_ids] = False
            # é‡ç½®å†å²å¥–åŠ±
            for key in self._prev_rewards:
                if self._prev_rewards[key] is not None:
                    self._prev_rewards[key][env_ids] = 0.0
        
        # 8.5 æ›´æ–°å›åˆè®¡æ•°å’Œè¯¾ç¨‹å­¦ä¹ é˜¶æ®µ
        if env_ids is not None and len(env_ids) > 0:
            self.episode_count += len(env_ids)
            # æ›´æ–°è¯¾ç¨‹å­¦ä¹ é˜¶æ®µ
            self._update_curriculum_stage()

        # 8.4 é‡ç½®åŠ¨ä½œç¼“å†²
        default_root_state = self._robot.data.default_root_state[env_ids]
        self._prev_dist_to_target[env_ids] = 0.0
        default_root_state[:, :3] += self.scene.env_origins[env_ids]
        self._robot.write_root_pose_to_sim(default_root_state[:, :7], env_ids)
        self._robot.write_root_velocity_to_sim(default_root_state[:, 7:], env_ids)
        if self.debug_draw:
            self.debug_draw.clear_lines()
        # ä½¿ç”¨è¯¾ç¨‹å­¦ä¹ çš„å‚æ•°
        if self.curriculum_enabled:
            stage_config = self.curriculum_stages[self.curriculum_stage]
            num_points = stage_config['num_waypoints']
            num_interp = stage_config['num_interp']
            step_size = stage_config['step_size']
        else:
            num_points = self.cfg.num_waypoints
            num_interp = self.cfg.num_interp
            step_size = self.cfg.step_size
            
        for i, env_id in enumerate(env_ids):
            start = self._robot.data.root_state_w[env_id, :2]

            # éšæœºç”Ÿæˆç»ˆç‚¹
            traj = self._trajectories[env_id]
            if self.finished_mask[env_id] or traj.abs().sum() == 0:
                traj = self.generate_random_walk_trajectory(start, num_points=num_points, num_interp=num_interp,
                                                         step_size=step_size, seed=random.randint(1, 100))
                self._trajectories[env_id] = traj
            self._current_wp_idx[env_id] = 0

            # å¯é€‰å¯è§†åŒ–
            if self.debug_draw:
                self.draw_spline(traj)
    
    def _apply_reward_smoothing(self, rewards: dict, target_switched: torch.Tensor) -> dict:
        """åº”ç”¨å¥–åŠ±å¹³æ»‘å¤„ç†ï¼Œè§£å†³ç›®æ ‡ç‚¹åˆ‡æ¢æ—¶çš„å¥–åŠ±çªå˜é—®é¢˜"""
        smoothed_rewards = {}
        
        for key, reward in rewards.items():
            # æ£€æŸ¥å½“å‰å¥–åŠ±çš„æ•°å€¼ç¨³å®šæ€§
            if torch.isnan(reward).any() or torch.isinf(reward).any():
                print(f"NaN/Inf found in {key} reward at step {self.global_step}, replacing with zeros")
                reward = torch.where(torch.isnan(reward) | torch.isinf(reward), torch.zeros_like(reward), reward)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰å†å²å¥–åŠ±æ•°æ®
            if key in self._prev_rewards and self._prev_rewards[key] is not None:
                # æ£€æŸ¥å†å²å¥–åŠ±çš„æ•°å€¼ç¨³å®šæ€§
                if torch.isnan(self._prev_rewards[key]).any() or torch.isinf(self._prev_rewards[key]).any():
                    print(f"NaN/Inf found in previous {key} reward at step {self.global_step}, resetting")
                    self._prev_rewards[key] = torch.zeros_like(reward)
                
                # æ ¹æ®æ˜¯å¦å‘ç”Ÿç›®æ ‡ç‚¹åˆ‡æ¢é€‰æ‹©å¹³æ»‘å› å­
                if target_switched.any():
                    # ç›®æ ‡ç‚¹åˆ‡æ¢æ—¶ä½¿ç”¨æ›´å¤§çš„å¹³æ»‘å› å­
                    smooth_factor = self.transition_smoothing_factor
                else:
                    # æ­£å¸¸æƒ…å†µä½¿ç”¨æ ‡å‡†å¹³æ»‘å› å­
                    smooth_factor = self.smoothing_factor
                
                # åº”ç”¨æŒ‡æ•°ç§»åŠ¨å¹³å‡å¹³æ»‘
                smoothed_reward = (1 - smooth_factor) * self._prev_rewards[key] + smooth_factor * reward
                smoothed_rewards[key] = smoothed_reward
            else:
                # ç¬¬ä¸€æ¬¡è®¡ç®—ï¼Œç›´æ¥ä½¿ç”¨å½“å‰å¥–åŠ±
                smoothed_rewards[key] = reward
            
            # æ›´æ–°å†å²å¥–åŠ±
            self._prev_rewards[key] = reward.clone()
        
        return smoothed_rewards
    
    def _check_numerical_stability(self, tensor, name, step=None):
        """æ£€æŸ¥å¼ é‡çš„æ•°å€¼ç¨³å®šæ€§ï¼Œå¹¶è®°å½•è¯¦ç»†çš„æº¯æºä¿¡æ¯ï¼Œå¹¶è‡ªåŠ¨ä¿®å¤NaN/Inf"""
        # æ£€æŸ¥æ˜¯å¦ä¸º torch.Tensor
        if not isinstance(tensor, torch.Tensor):
            return tensor
        
        # ç«‹å³æ£€æµ‹NaN/Infï¼ˆä¸ä¾èµ–debug_modeï¼Œç¡®ä¿æ€»æ˜¯æ£€æµ‹ï¼‰
        has_nan = torch.isnan(tensor).any()
        has_inf = torch.isinf(tensor).any()
        
        # ä¿å­˜åŸå§‹tensorç”¨äºè°ƒè¯•ï¼ˆåœ¨ä¿®å¤å‰ï¼‰
        original_tensor = tensor.clone() if (has_nan or has_inf) else None
        
        # å¦‚æœæ£€æµ‹åˆ°NaN/Infï¼Œç«‹å³ä¿®å¤ï¼ˆæ›¿æ¢ä¸ºé›¶ï¼‰
        if has_nan or has_inf:
            # ç«‹å³ä¿®å¤ï¼Œé˜²æ­¢NaNä¼ æ’­
            tensor = torch.where(torch.isnan(tensor) | torch.isinf(tensor), 
                               torch.zeros_like(tensor), tensor)
        
        # è®°å½•å’Œæ‰“å°ä¿¡æ¯ï¼ˆä½¿ç”¨åŸå§‹tensorï¼Œåœ¨ä¿®å¤å‰æ”¶é›†ä¿¡æ¯ï¼‰
        if (has_nan or has_inf) and hasattr(self, '_always_check_nan') and self._always_check_nan:
            if step is None:
                step = getattr(self, 'global_step', 0)
            
            # åˆå§‹åŒ–è®¡æ•°å­—å…¸ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            if not hasattr(self, 'nan_inf_count'):
                self.nan_inf_count = {}
            if name not in self.nan_inf_count:
                self.nan_inf_count[name] = 0
                
            self.nan_inf_count[name] += 1
            
            # è·å–è°ƒç”¨æ ˆä¿¡æ¯ï¼ˆè·³è¿‡å½“å‰å‡½æ•°å’Œè°ƒç”¨å®ƒçš„å‡½æ•°ï¼‰
            stack = traceback.extract_stack()
            # è·å–è°ƒç”¨è€…çš„ä¿¡æ¯ï¼ˆè·³è¿‡å½“å‰å‡½æ•°å’Œè°ƒç”¨å®ƒçš„å‡½æ•°ï¼‰
            caller_info = stack[-3] if len(stack) >= 3 else stack[-2] if len(stack) >= 2 else None
            
            # æ”¶é›†è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯ï¼ˆä½¿ç”¨åŸå§‹tensorï¼Œä¿®å¤å‰çš„ï¼‰
            debug_tensor = original_tensor if original_tensor is not None else tensor
            nan_count = torch.isnan(debug_tensor).sum().item() if has_nan else 0
            inf_count = torch.isinf(debug_tensor).sum().item() if has_inf else 0
            total_elements = debug_tensor.numel()
            
            # è·å–æœ‰æ•ˆå€¼çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆæ’é™¤NaN/Infï¼‰
            valid_tensor = debug_tensor[~(torch.isnan(debug_tensor) | torch.isinf(debug_tensor))]
            if len(valid_tensor) > 0:
                valid_min = valid_tensor.min().item()
                valid_max = valid_tensor.max().item()
                valid_mean = valid_tensor.mean().item()
                valid_std = valid_tensor.std().item()
            else:
                valid_min = valid_max = valid_mean = valid_std = float('nan')
            
            # æ„å»ºæº¯æºä¿¡æ¯
            trace_info = {
                'step': step,
                'variable_name': name,
                'has_nan': has_nan,
                'has_inf': has_inf,
                'nan_count': nan_count,
                'inf_count': inf_count,
                'total_elements': total_elements,
                # é˜²æ­¢é™¤ä»¥é›¶ï¼šç¡®ä¿total_elements > 0
                'nan_ratio': float(nan_count) / float(total_elements) if total_elements > 0 else 0.0,
                'inf_ratio': float(inf_count) / float(total_elements) if total_elements > 0 else 0.0,
                'shape': list(debug_tensor.shape),
                'dtype': str(debug_tensor.dtype),
                'device': str(debug_tensor.device),
                'valid_min': valid_min,
                'valid_max': valid_max,
                'valid_mean': valid_mean,
                'valid_std': valid_std,
                'caller_file': caller_info.filename if caller_info else 'unknown',
                'caller_line': caller_info.lineno if caller_info else 0,
                'caller_function': caller_info.name if caller_info else 'unknown',
                'caller_code': caller_info.line if caller_info else 'unknown',
                'total_occurrences': self.nan_inf_count[name],
                'timestamp': time.time()
            }
            
            # è®°å½•åˆ°æº¯æºæ—¥å¿—
            self.nan_trace_log.append(trace_info)
            # åªä¿ç•™æœ€è¿‘1000æ¡è®°å½•ï¼Œé¿å…å†…å­˜æº¢å‡º
            if len(self.nan_trace_log) > 1000:
                self.nan_trace_log = self.nan_trace_log[-1000:]
            
            # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡å‡ºç°ï¼Œè®°å½•åˆ°é¦–æ¬¡å‡ºç°å­—å…¸
            if name not in self.nan_first_occurrence:
                self.nan_first_occurrence[name] = trace_info.copy()
                self.nan_first_occurrence[name]['is_first'] = True
            
            # æ‰“å°è¯¦ç»†çš„æº¯æºä¿¡æ¯
            print(f"\n{'='*80}")
            print(f"âš ï¸  NaN/Inf æ£€æµ‹åˆ°! å˜é‡: {name}")
            print(f"{'='*80}")
            print(f"æ­¥éª¤: {step} | æ€»è®¡å‡ºç°æ¬¡æ•°: {self.nan_inf_count[name]}")
            # é˜²æ­¢é™¤ä»¥é›¶ï¼šè®¡ç®—ç™¾åˆ†æ¯”å‰æ£€æŸ¥
            nan_pct = (nan_count / total_elements * 100) if total_elements > 0 else 0.0
            inf_pct = (inf_count / total_elements * 100) if total_elements > 0 else 0.0
            print(f"NaNæ•°é‡: {nan_count}/{total_elements} ({nan_pct:.2f}%)")
            print(f"Infæ•°é‡: {inf_count}/{total_elements} ({inf_pct:.2f}%)")
            print(f"å½¢çŠ¶: {debug_tensor.shape} | ç±»å‹: {debug_tensor.dtype} | è®¾å¤‡: {debug_tensor.device}")
            
            if len(valid_tensor) > 0:
                print(f"æœ‰æ•ˆå€¼èŒƒå›´: [{valid_min:.6f}, {valid_max:.6f}]")
                print(f"æœ‰æ•ˆå€¼å‡å€¼: {valid_mean:.6f} Â± {valid_std:.6f}")
            else:
                print("âš ï¸  è­¦å‘Š: æ‰€æœ‰å€¼éƒ½æ˜¯NaNæˆ–Inf!")
            
            if caller_info:
                print(f"\nè°ƒç”¨ä½ç½®:")
                print(f"  æ–‡ä»¶: {caller_info.filename}")
                print(f"  è¡Œå·: {caller_info.lineno}")
                print(f"  å‡½æ•°: {caller_info.name}")
                print(f"  ä»£ç : {caller_info.line}")
            
            # å¦‚æœæ˜¯ç¬¬ä¸€æ¬¡å‡ºç°ï¼Œç‰¹åˆ«æ ‡æ³¨
            if name in self.nan_first_occurrence and self.nan_first_occurrence[name].get('is_first'):
                print(f"\nğŸ” è¿™æ˜¯å˜é‡ '{name}' ç¬¬ä¸€æ¬¡å‡ºç° NaN/Inf")
                self.nan_first_occurrence[name]['is_first'] = False
            
            print(f"{'='*80}\n")
            
            # å†æ¬¡ç¡®ä¿æ›¿æ¢NaNå’ŒInfå€¼ï¼ˆåŒé‡ä¿é™©ï¼‰
            tensor = torch.where(torch.isnan(tensor) | torch.isinf(tensor), 
                               torch.zeros_like(tensor), tensor)
        
        # æœ€ç»ˆéªŒè¯ï¼šç¡®ä¿è¿”å›çš„å¼ é‡æ²¡æœ‰NaN/Inf
        if isinstance(tensor, torch.Tensor):
            if torch.isnan(tensor).any() or torch.isinf(tensor).any():
                print(f"âš ï¸  è­¦å‘Šï¼š{name} åœ¨ä¿®å¤åä»æœ‰NaN/Infï¼Œå¼ºåˆ¶æ›¿æ¢ä¸ºé›¶")
                tensor = torch.where(torch.isnan(tensor) | torch.isinf(tensor), 
                                   torch.zeros_like(tensor), tensor)
        
        return tensor
    
    def _safe_add_scalar(self, tag, scalar_value, global_step, default_value=0.0):
        """å®‰å…¨åœ°è®°å½•æ ‡é‡å€¼åˆ°TensorBoardï¼Œè‡ªåŠ¨å¤„ç†NaN/Inf"""
        # æ£€æŸ¥æ˜¯å¦ä¸ºtorch.Tensor
        if isinstance(scalar_value, torch.Tensor):
            if scalar_value.numel() == 1:
                scalar_value = scalar_value.item()
            else:
                # å¦‚æœæ˜¯å¤šå…ƒç´ å¼ é‡ï¼Œè®¡ç®—å‡å€¼
                scalar_value = scalar_value.mean().item()
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºNaNæˆ–Inf
        is_invalid = (scalar_value is None or 
                     (isinstance(scalar_value, float) and 
                      (math.isnan(scalar_value) or math.isinf(scalar_value))))
        
        if is_invalid:
            # å¦‚æœå€¼ä¸ºNaN/Infï¼Œä½¿ç”¨é»˜è®¤å€¼å¹¶è®°å½•è­¦å‘Š
            if hasattr(self, 'nan_inf_count'):
                if 'tensorboard' not in self.nan_inf_count:
                    self.nan_inf_count['tensorboard'] = 0
                self.nan_inf_count['tensorboard'] += 1
            scalar_value = default_value
        
        # è®°å½•åˆ°TensorBoard
        if hasattr(self, 'writer') and self.writer is not None:
            try:
                self.writer.add_scalar(tag, scalar_value, global_step)
            except Exception as e:
                # å¦‚æœè®°å½•å¤±è´¥ï¼Œæ‰“å°è­¦å‘Šä½†ä¸ä¸­æ–­è®­ç»ƒ
                print(f"è­¦å‘Šï¼šæ— æ³•è®°å½• {tag} åˆ°TensorBoard: {e}")
        
        return scalar_value
    
    def _init_curriculum_parameters(self):
        """åˆå§‹åŒ–è¯¾ç¨‹å­¦ä¹ å‚æ•°"""
        if not self.curriculum_enabled:
            return
        
        # åº”ç”¨å½“å‰é˜¶æ®µçš„å‚æ•°
        self._apply_curriculum_stage_config()
        
        # è®°å½•è¯¾ç¨‹å­¦ä¹ ä¿¡æ¯
        print(f"\n{'='*80}")
        print(f"è¯¾ç¨‹å­¦ä¹ å·²å¯ç”¨")
        print(f"å½“å‰é˜¶æ®µ: {self.curriculum_stage} - {self.curriculum_stages[self.curriculum_stage]['stage_name']}")
        print(f"æˆåŠŸç‡é˜ˆå€¼: {self.curriculum_success_rate_threshold:.1%}")
        print(f"çª—å£å¤§å°: {self.curriculum_success_window_size} å›åˆ")
        print(f"å„é˜¶æ®µæœ€å°å›åˆæ•°: {self.curriculum_min_episodes_per_stage}")
        print(f"{'='*80}\n")
    
    def _update_curriculum_stage(self):
        """æ›´æ–°è¯¾ç¨‹å­¦ä¹ é˜¶æ®µ"""
        if not self.curriculum_enabled:
            return
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦åˆ‡æ¢é˜¶æ®µ
        old_stage = self.curriculum_stage
        new_stage = self._determine_curriculum_stage()
        
        if new_stage != old_stage:
            self.curriculum_stage = new_stage
            self._apply_curriculum_stage_config()
            self._log_curriculum_stage_change(old_stage, new_stage)
    
    def _determine_curriculum_stage(self):
        """ç¡®å®šå½“å‰åº”è¯¥å¤„äºçš„è¯¾ç¨‹é˜¶æ®µï¼ˆåŸºäºæˆåŠŸç‡å’Œæœ€å°å›åˆæ•°ï¼‰"""
        # è®¡ç®—å½“å‰é˜¶æ®µçš„çª—å£æˆåŠŸç‡
        window_success_rate = self._get_window_success_rate()
        
        # è·å–å½“å‰é˜¶æ®µçš„æœ€å°å›åˆæ•°
        min_episodes = self.curriculum_min_episodes_per_stage[self.curriculum_stage]
        
        # åˆ¤æ–­æ˜¯å¦å¯ä»¥åˆ‡æ¢åˆ°ä¸‹ä¸€é˜¶æ®µ
        can_progress = (
            window_success_rate >= self.curriculum_success_rate_threshold and
            self.curriculum_stats[f'stage_{self.curriculum_stage}_steps'] >= min_episodes
        )
        
        # å¦‚æœå½“å‰é˜¶æ®µå·²è¾¾æ ‡ï¼Œå°è¯•åˆ‡æ¢åˆ°ä¸‹ä¸€é˜¶æ®µ
        if can_progress and self.curriculum_stage < 2:
            return self.curriculum_stage + 1
        
        # å¦åˆ™ä¿æŒå½“å‰é˜¶æ®µ
        return self.curriculum_stage
    
    def _get_window_success_rate(self):
        """è®¡ç®—æœ€è¿‘çª—å£æœŸå†…çš„æˆåŠŸç‡"""
        if len(self.success_history) < 10:  # è‡³å°‘éœ€è¦10ä¸ªæ ·æœ¬
            return 0.0
        
        # å–æœ€è¿‘çª—å£æœŸçš„æˆåŠŸ/å¤±è´¥è®°å½•
        recent_history = self.success_history[-self.curriculum_success_window_size:]
        if len(recent_history) == 0:
            return 0.0
        
        # è®¡ç®—æˆåŠŸç‡ï¼ˆç¡®ä¿æ•°å€¼ç¨³å®šæ€§ï¼‰
        success_count = sum(recent_history)
        if success_count < 0 or len(recent_history) <= 0:
            return 0.0
        
        # é˜²æ­¢é™¤ä»¥é›¶ï¼šå¦‚æœå†å²è®°å½•ä¸ºç©ºï¼Œè¿”å›0
        history_len = len(recent_history)
        if history_len == 0:
            success_rate = 0.0
        else:
            success_rate = float(success_count) / float(history_len)
        
        # ç¡®ä¿è¿”å›çš„å€¼åœ¨æœ‰æ•ˆèŒƒå›´å†…ï¼Œå¹¶ä¸”ä¸æ˜¯NaNæˆ–Inf
        if math.isnan(success_rate) or math.isinf(success_rate):
            return 0.0
        
        # é™åˆ¶åœ¨ [0, 1] èŒƒå›´å†…
        success_rate = max(0.0, min(1.0, success_rate))
        return success_rate
    
    def _apply_curriculum_stage_config(self):
        """åº”ç”¨å½“å‰è¯¾ç¨‹é˜¶æ®µçš„é…ç½®"""
        if not self.curriculum_enabled:
            return
        
        stage_config = self.curriculum_stages[self.curriculum_stage]
        
        # æ›´æ–°ç¯å¢ƒå‚æ•°
        self.cfg.num_waypoints = stage_config['num_waypoints']
        self.cfg.num_interp = stage_config['num_interp']
        self.cfg.step_size = stage_config['step_size']
        self.cfg.episode_length_s = stage_config['episode_length_s']
        
        # æ›´æ–°å¥–åŠ±æƒé‡
        self.cfg.traj_track_scale = stage_config['traj_track_scale']
        self.cfg.lateral_error_scale = stage_config['lateral_error_scale']
        self.cfg.direction_scale = stage_config['direction_scale']
        
        # é‡æ–°åˆå§‹åŒ–è½¨è¿¹å¼ é‡ä»¥é€‚åº”æ–°çš„å‚æ•°
        new_traj_size = self.cfg.num_waypoints * self.cfg.num_interp
        if self._trajectories.shape[1] != new_traj_size:
            print(f"é‡æ–°åˆå§‹åŒ–è½¨è¿¹å¼ é‡: {self._trajectories.shape[1]} -> {new_traj_size}")
            self._trajectories = torch.zeros(self.num_envs, new_traj_size, 2, device=self.device)
            # é‡ç½®æ‰€æœ‰ç¯å¢ƒçš„è½¨è¿¹
            self._reset_trajectories_all()
        
        # æ³¨æ„ï¼šmax_episode_length æ˜¯åªè¯»å±æ€§ï¼Œé€šè¿‡ä¿®æ”¹ cfg.episode_length_s æ¥é—´æ¥æ›´æ–°
        # self.max_episode_length ä¼šåœ¨çˆ¶ç±»ä¸­è‡ªåŠ¨è®¡ç®—
    
    def _reset_trajectories_all(self):
        """é‡ç½®æ‰€æœ‰ç¯å¢ƒçš„è½¨è¿¹"""
        for env_id in range(self.num_envs):
            start = self._robot.data.root_state_w[env_id, :2]
            traj = self.generate_random_walk_trajectory(
                start, 
                num_points=self.cfg.num_waypoints, 
                num_interp=self.cfg.num_interp,
                step_size=self.cfg.step_size, 
                seed=random.randint(1, 100)
            )
            self._trajectories[env_id] = traj
            self._current_wp_idx[env_id] = 0
    
    def _log_curriculum_stage_change(self, old_stage, new_stage):
        """è®°å½•è¯¾ç¨‹é˜¶æ®µåˆ‡æ¢"""
        old_name = self.curriculum_stages[old_stage]['stage_name']
        new_name = self.curriculum_stages[new_stage]['stage_name']
        
        # è·å–åˆ‡æ¢æ—¶çš„æˆåŠŸç‡ä¿¡æ¯
        window_success_rate = self._get_window_success_rate()
        old_stage_steps = self.curriculum_stats[f'stage_{old_stage}_steps']
        
        print(f"è¯¾ç¨‹å­¦ä¹ é˜¶æ®µåˆ‡æ¢: {old_stage}({old_name}) -> {new_stage}({new_name}) at episode {self.episode_count}")
        print(f"  æˆåŠŸç‡: {window_success_rate:.2%}, {old_stage}é˜¶æ®µå›åˆæ•°: {old_stage_steps}")
        
        # è®°å½•åˆ°TensorBoard
        if hasattr(self, 'writer'):
            self._safe_add_scalar("Curriculum/Stage", new_stage, self.global_step)
            self._safe_add_scalar("Curriculum/Stage_Change", 1.0, self.global_step)
    
    def _update_curriculum_stats(self, episode_success):
        """æ›´æ–°è¯¾ç¨‹å­¦ä¹ ç»Ÿè®¡"""
        if not self.curriculum_enabled:
            return
        
        # æ›´æ–°å½“å‰é˜¶æ®µçš„æ­¥æ•°
        stage_key = f'stage_{self.curriculum_stage}_steps'
        self.curriculum_stats[stage_key] += 1
        
        # æ·»åŠ æˆåŠŸç‡å†å²è®°å½•
        self.success_history.append(1.0 if episode_success else 0.0)
        # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…ï¼ˆæœ€å¤šä¿ç•™5000ä¸ªæ ·æœ¬ï¼‰
        if len(self.success_history) > 5000:
            self.success_history = self.success_history[-5000:]
        
        # æ›´æ–°æˆåŠŸç‡ï¼ˆä½¿ç”¨æŒ‡æ•°ç§»åŠ¨å¹³å‡ï¼‰
        success_rate_key = f'stage_{self.curriculum_stage}_success_rate'
        alpha = 0.01  # å¹³æ»‘å› å­
        current_success_rate = self.curriculum_stats[success_rate_key]
        new_success_rate = (1 - alpha) * current_success_rate + alpha * (1.0 if episode_success else 0.0)
        self.curriculum_stats[success_rate_key] = new_success_rate
        
        # è®¡ç®—çª—å£æˆåŠŸç‡
        window_success_rate = self._get_window_success_rate()
        
        # è®°å½•åˆ°TensorBoardï¼ˆä½¿ç”¨å®‰å…¨æ–¹æ³•é˜²æ­¢NaN/Infï¼‰
        if hasattr(self, 'writer'):
            self._safe_add_scalar(f"Curriculum/Stage_{self.curriculum_stage}_Success_Rate", 
                                 new_success_rate, self.global_step)
            self._safe_add_scalar(f"Curriculum/Stage_{self.curriculum_stage}_Steps", 
                                 self.curriculum_stats[stage_key], self.global_step)
            self._safe_add_scalar(f"Curriculum/Stage_{self.curriculum_stage}_Window_Success_Rate", 
                                 window_success_rate, self.global_step)
            self._safe_add_scalar("Curriculum/Overall_Window_Success_Rate", 
                                 window_success_rate, self.global_step)
            can_progress_val = (1.0 if (window_success_rate >= self.curriculum_success_rate_threshold 
                                       and self.curriculum_stats[stage_key] >= self.curriculum_min_episodes_per_stage[self.curriculum_stage]) else 0.0)
            self._safe_add_scalar("Curriculum/Can_Progress", can_progress_val, self.global_step)
    
    def get_curriculum_info(self):
        """è·å–è¯¾ç¨‹å­¦ä¹ ä¿¡æ¯"""
        if not self.curriculum_enabled:
            return {"enabled": False}
        
        current_stage = self.curriculum_stages[self.curriculum_stage]
        return {
            "enabled": True,
            "current_stage": self.curriculum_stage,
            "stage_name": current_stage['stage_name'],
            "num_waypoints": current_stage['num_waypoints'],
            "num_interp": current_stage['num_interp'],
            "step_size": current_stage['step_size'],
            "episode_length_s": current_stage['episode_length_s'],
            "stats": self.curriculum_stats.copy()
        }
    
    def get_nan_trace_summary(self, variable_name=None, recent_only=True, max_items=50):
        """è·å–NaN/Infæº¯æºæ‘˜è¦
        
        Args:
            variable_name: å¦‚æœæŒ‡å®šï¼Œåªè¿”å›è¯¥å˜é‡çš„æº¯æºä¿¡æ¯
            recent_only: æ˜¯å¦åªè¿”å›æœ€è¿‘çš„è®°å½•
            max_items: æœ€å¤§è¿”å›è®°å½•æ•°
        
        Returns:
            åŒ…å«æº¯æºä¿¡æ¯çš„å­—å…¸
        """
        if not hasattr(self, 'nan_trace_log'):
            return {"error": "æº¯æºç³»ç»Ÿæœªåˆå§‹åŒ–"}
        
        # ç­›é€‰è®°å½•
        filtered_log = self.nan_trace_log
        if variable_name:
            filtered_log = [log for log in self.nan_trace_log if log['variable_name'] == variable_name]
        
        # å¦‚æœåªè¿”å›æœ€è¿‘çš„
        if recent_only:
            filtered_log = filtered_log[-max_items:]
        
        # ç»Ÿè®¡æ‘˜è¦
        summary = {
            "total_events": len(self.nan_trace_log),
            "filtered_events": len(filtered_log),
            "variables_with_nan": list(set(log['variable_name'] for log in self.nan_trace_log)),
            "first_occurrences": {},
            "recent_traces": filtered_log[-max_items:] if filtered_log else []
        }
        
        # æ·»åŠ æ¯ä¸ªå˜é‡çš„é¦–æ¬¡å‡ºç°ä¿¡æ¯
        for var_name, first_info in self.nan_first_occurrence.items():
            summary["first_occurrences"][var_name] = {
                "first_step": first_info.get('step', 0),
                "first_caller": first_info.get('caller_function', 'unknown'),
                "first_file": first_info.get('caller_file', 'unknown'),
                "first_line": first_info.get('caller_line', 0),
                "total_count": self.nan_inf_count.get(var_name, 0)
            }
        
        return summary
    
    def print_nan_trace_summary(self, variable_name=None):
        """æ‰“å°NaN/Infæº¯æºæ‘˜è¦åˆ°æ§åˆ¶å°"""
        summary = self.get_nan_trace_summary(variable_name=variable_name)
        
        print(f"\n{'='*80}")
        print(f"NaN/Inf æº¯æºæ‘˜è¦")
        print(f"{'='*80}")
        print(f"æ€»äº‹ä»¶æ•°: {summary['total_events']}")
        print(f"æ¶‰åŠå˜é‡æ•°: {len(summary['variables_with_nan'])}")
        print(f"\næ¶‰åŠçš„å˜é‡: {', '.join(summary['variables_with_nan'])}")
        
        print(f"\n{'='*80}")
        print(f"é¦–æ¬¡å‡ºç°ä½ç½®:")
        print(f"{'='*80}")
        for var_name, info in summary['first_occurrences'].items():
            print(f"\nå˜é‡: {var_name}")
            print(f"  é¦–æ¬¡å‡ºç°æ­¥æ•°: {info['first_step']}")
            print(f"  æ€»è®¡å‡ºç°æ¬¡æ•°: {info['total_count']}")
            print(f"  é¦–æ¬¡è°ƒç”¨ä½ç½®:")
            print(f"    æ–‡ä»¶: {info['first_file']}")
            print(f"    è¡Œå·: {info['first_line']}")
            print(f"    å‡½æ•°: {info['first_caller']}")
        
        if summary['recent_traces']:
            print(f"\n{'='*80}")
            print(f"æœ€è¿‘ {len(summary['recent_traces'])} æ¬¡äº‹ä»¶:")
            print(f"{'='*80}")
            for i, trace in enumerate(summary['recent_traces'][-10:], 1):  # åªæ˜¾ç¤ºæœ€è¿‘10æ¬¡
                print(f"\näº‹ä»¶ #{i}:")
                print(f"  å˜é‡: {trace['variable_name']}")
                print(f"  æ­¥æ•°: {trace['step']}")
                print(f"  NaN: {trace['nan_count']}/{trace['total_elements']} ({trace['nan_ratio']*100:.2f}%)")
                print(f"  Inf: {trace['inf_count']}/{trace['total_elements']} ({trace['inf_ratio']*100:.2f}%)")
                print(f"  ä½ç½®: {trace['caller_file']}:{trace['caller_line']} in {trace['caller_function']}()")
        
        print(f"{'='*80}\n")
    
    def export_nan_trace_to_file(self, filepath, variable_name=None):
        """å¯¼å‡ºNaN/Infæº¯æºä¿¡æ¯åˆ°JSONæ–‡ä»¶"""
        import json
        
        summary = self.get_nan_trace_summary(variable_name=variable_name, recent_only=False)
        
        # ç¡®ä¿æ–‡ä»¶è·¯å¾„å­˜åœ¨
        import os
        os.makedirs(os.path.dirname(filepath) if os.path.dirname(filepath) else '.', exist_ok=True)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        print(f"NaN/Inf æº¯æºä¿¡æ¯å·²å¯¼å‡ºåˆ°: {filepath}")
        return filepath