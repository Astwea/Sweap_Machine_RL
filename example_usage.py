#!/usr/bin/env python3
"""
ä¼˜åŒ–é›†æˆä½¿ç”¨ç¤ºä¾‹
"""

import sys
import os
import torch

# æ·»åŠ è·¯å¾„
sys.path.append('/home/astwea/MyDogTask/Mydog')
sys.path.append('/home/astwea/IsaacLab/source/isaaclab')

def example_basic_usage():
    """åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹"""
    print("=== åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹ ===")
    
    from integrated_optimizations import IntegratedOptimizations
    from Mydog.tasks.direct.mydog_marl.mydog_marl_env_cfg import MydogMarlEnvCfg
    
    # 1. åˆ›å»ºé…ç½®
    cfg = MydogMarlEnvCfg()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    # 2. åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = IntegratedOptimizations(device, cfg)
    
    # 3. æ¨¡æ‹Ÿç¯å¢ƒçŠ¶æ€
    num_envs = 8
    env_state = {
        'positions': torch.randn(num_envs, 2, device=device),
        'lin_vel': torch.randn(num_envs, 2, device=device),
        'ang_vel': torch.randn(num_envs, 1, device=device),
        'yaw': torch.randn(num_envs, device=device),
        'current_target': torch.randn(num_envs, 2, device=device),
        'next_target': torch.randn(num_envs, 2, device=device),
        'episode_length': torch.randint(0, 100, (num_envs,), device=device),
        'max_episode_length': torch.tensor(100, device=device),
        'current_wp_idx': torch.randint(0, 10, (num_envs,), device=device),
        'total_waypoints': 10,
        'actions': torch.randn(num_envs, 2, device=device),
        'prev_positions': torch.randn(num_envs, 2, device=device),
    }
    
    actions = torch.randn(num_envs, 2, device=device)
    prev_actions = torch.randn(num_envs, 2, device=device)
    
    # 4. è®¡ç®—ä¼˜åŒ–çš„è§‚æµ‹
    obs = optimizer.get_optimized_observations(env_state, actions, prev_actions)
    print(f"è§‚æµ‹å½¢çŠ¶: {obs.shape}")
    
    # 5. è®¡ç®—ä¼˜åŒ–çš„å¥–åŠ±
    total_reward, rewards = optimizer.compute_optimized_rewards(
        env_state, actions, prev_actions
    )
    print(f"æ€»å¥–åŠ±å½¢çŠ¶: {total_reward.shape}")
    print(f"å¥–åŠ±ç»„ä»¶: {list(rewards.keys())}")
    
    return True

def example_training_integration():
    """è®­ç»ƒé›†æˆç¤ºä¾‹"""
    print("\n=== è®­ç»ƒé›†æˆç¤ºä¾‹ ===")
    
    from integrated_optimizations import IntegratedOptimizations
    from Mydog.tasks.direct.mydog_marl.mydog_marl_env_cfg import MydogMarlEnvCfg
    
    # æ¨¡æ‹Ÿè®­ç»ƒå¾ªç¯
    cfg = MydogMarlEnvCfg()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    optimizer = IntegratedOptimizations(device, cfg)
    
    # æ¨¡æ‹Ÿå¤šä¸ªepisode
    for episode in range(5):
        print(f"\nEpisode {episode + 1}:")
        
        # æ¨¡æ‹Ÿepisodeæ•°æ®
        episode_reward = 0
        episode_length = 0
        success = False
        
        for step in range(20):  # æ¨¡æ‹Ÿ20æ­¥
            # æ¨¡æ‹Ÿç¯å¢ƒçŠ¶æ€
            env_state = {
                'positions': torch.randn(4, 2, device=device),
                'lin_vel': torch.randn(4, 2, device=device),
                'ang_vel': torch.randn(4, 1, device=device),
                'yaw': torch.randn(4, device=device),
                'current_target': torch.randn(4, 2, device=device),
                'next_target': torch.randn(4, 2, device=device),
                'episode_length': torch.tensor(step, device=device),
                'max_episode_length': torch.tensor(20, device=device),
                'prev_positions': torch.randn(4, 2, device=device),
            }
            
            actions = torch.randn(4, 2, device=device)
            prev_actions = torch.randn(4, 2, device=device)
            
            # è®¡ç®—å¥–åŠ±
            total_reward, rewards = optimizer.compute_optimized_rewards(
                env_state, actions, prev_actions
            )
            
            episode_reward += total_reward.mean().item()
            episode_length += 1
        
        # æ¨¡æ‹Ÿepisodeç»“æŸ
        success = episode_reward > 0  # ç®€å•çš„æˆåŠŸåˆ¤æ–­
        
        # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
        optimizer.update_performance_metrics(episode_reward, episode_length, success)
        
        print(f"  - å¥–åŠ±: {episode_reward:.2f}")
        print(f"  - é•¿åº¦: {episode_length}")
        print(f"  - æˆåŠŸ: {success}")
    
    # è·å–è®­ç»ƒå»ºè®®
    recommendations = optimizer.get_training_recommendations()
    if recommendations:
        print(f"\nè®­ç»ƒå»ºè®®: {recommendations}")
    
    return True

def example_adaptive_parameters():
    """è‡ªé€‚åº”å‚æ•°ç¤ºä¾‹"""
    print("\n=== è‡ªé€‚åº”å‚æ•°ç¤ºä¾‹ ===")
    
    from integrated_optimizations import IntegratedOptimizations
    from Mydog.tasks.direct.mydog_marl.mydog_marl_env_cfg import MydogMarlEnvCfg
    
    cfg = MydogMarlEnvCfg()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    optimizer = IntegratedOptimizations(device, cfg)
    
    print("åˆå§‹å‚æ•°:")
    print(f"  - å­¦ä¹ ç‡å€æ•°: {optimizer.adaptive_params['learning_rate_multiplier']}")
    print(f"  - æ¢ç´¢å€æ•°: {optimizer.adaptive_params['exploration_multiplier']}")
    
    # æ¨¡æ‹Ÿæ€§èƒ½æ•°æ®
    for i in range(10):
        success = i < 5  # å‰5ä¸ªepisodeæˆåŠŸ
        optimizer.update_performance_metrics(10.0 + i, 20, success)
    
    # è‡ªé€‚åº”å‚æ•°æ›´æ–°
    optimizer.adaptive_parameter_update()
    
    print("\næ›´æ–°åå‚æ•°:")
    print(f"  - å­¦ä¹ ç‡å€æ•°: {optimizer.adaptive_params['learning_rate_multiplier']:.3f}")
    print(f"  - æ¢ç´¢å€æ•°: {optimizer.adaptive_params['exploration_multiplier']:.3f}")
    
    # è·å–è¯¾ç¨‹å­¦ä¹ éš¾åº¦
    difficulty = optimizer.get_curriculum_difficulty()
    print(f"  - è¯¾ç¨‹éš¾åº¦: {difficulty:.3f}")
    
    # è·å–æ¢ç´¢epsilon
    epsilon = optimizer.get_exploration_epsilon(1000)
    print(f"  - æ¢ç´¢epsilon: {epsilon:.3f}")
    
    return True

def example_observation_analysis():
    """è§‚æµ‹åˆ†æç¤ºä¾‹"""
    print("\n=== è§‚æµ‹åˆ†æç¤ºä¾‹ ===")
    
    from integrated_optimizations import IntegratedOptimizations
    from Mydog.tasks.direct.mydog_marl.mydog_marl_env_cfg import MydogMarlEnvCfg
    
    cfg = MydogMarlEnvCfg()
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    optimizer = IntegratedOptimizations(device, cfg)
    
    # è·å–è§‚æµ‹ç©ºé—´ä¿¡æ¯
    obs_info = optimizer.observation_space.get_observation_info()
    
    print("è§‚æµ‹ç©ºé—´ä¿¡æ¯:")
    print(f"  - æ€»ç»´åº¦: {obs_info['total_dim']}")
    print(f"  - ç»„ä»¶: {obs_info['dimensions']}")
    
    print("\nç»„ä»¶æè¿°:")
    for key, desc in obs_info['description'].items():
        print(f"  - {key}: {desc}")
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ ä¼˜åŒ–é›†æˆä½¿ç”¨ç¤ºä¾‹")
    print("=" * 50)
    
    examples = [
        example_basic_usage,
        example_training_integration,
        example_adaptive_parameters,
        example_observation_analysis,
    ]
    
    for example in examples:
        try:
            example()
        except Exception as e:
            print(f"âŒ ç¤ºä¾‹ {example.__name__} å¤±è´¥: {e}")
    
    print("\nğŸ‰ æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")

if __name__ == "__main__":
    main()
